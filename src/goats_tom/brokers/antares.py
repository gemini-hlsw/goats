__all__ = ["ANTARESBrokerForm", "ANTARESBroker"]

import logging
from typing import Any, Iterator

import marshmallow
import pandas as pd
from astropy.time import Time, TimezoneInfo
from crispy_forms.layout import HTML, Div, Fieldset, Layout
from django import forms
from django.core.files.base import ContentFile
from django.db import IntegrityError, transaction
from django.forms.widgets import Textarea
from django.templatetags.static import static
from tom_alerts.alerts import GenericAlert, GenericBroker, GenericQueryForm
from tom_dataproducts.data_processor import run_data_processor
from tom_dataproducts.exceptions import InvalidFileFormatException
from tom_dataproducts.models import DataProduct, ReducedDatum
from tom_targets.models import BaseTarget, Target, TargetName

from goats_tom.antares_client.client import get_by_id, search
from goats_tom.antares_client.config import ANTARESConfig

logger = logging.getLogger(__name__)


class ANTARESBrokerForm(GenericQueryForm):
    """A Django form class.

    Attributes
    ----------
    query : JSONField
        A JSON field required for receiving Elastic Search queries.

    """

    query = forms.JSONField(
        required=False,
        label="Elastic Search query in JSON format",
        widget=Textarea(
            attrs={"rows": 10},
        ),
        initial={"query": {}},
    )

    class Media:
        # Incorporating additional JavaScript file.
        js = (static("js/query.js"),)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Defining layout and helper configurations along with initializing
        # URLs for images.
        self.common_layout = Layout("broker")
        chrome_img_url = static("img/chrome.png")
        firefox_img_url = static("img/firefox.png")
        firefox_extension_url = (
            "https://addons.mozilla.org/en-US/firefox/addon/antares2goats/"
        )
        chrome_extension_url = "https://chromewebstore.google.com/detail/antares2goats/nmnbkpfjnpachfajklpjimbdpkoebcba"

        # ruff: noqa: E501
        self.helper.layout = Layout(
            self.common_layout,
            HTML(
                """
                <p>
                Users can query objects in the ANTARES database using one of the following
                two methods: <br><br>1. Using the antares2goats Browser Extension (recommended).<br>2.
                An advanced
                query with Elastic Search syntax.
            </p>
            """,
            ),
            HTML(
                '<hr/><p style="font-size: 1.5rem;">Using the ANTARES portal with antares2goats</p>',
            ),
            Div(
                Div(
                    HTML(
                        f"""
                        <p>
                        Click <a href="{ANTARESConfig.get_url()}" target="_blank">this link</a> or the image below to open ANTARES in a new tab.
                        </p>
                        <div class="ratio ratio-21x9 position-relative">
                        <iframe src="{ANTARESConfig.get_url()}" scrolling="no" style="pointer-events: none;"></iframe>
                        <a href="{ANTARESConfig.get_url()}" target="_blank" class="stretched-link"></a>
                        </div>
                    """,
                    ),
                    css_class="col-md-12",
                ),
                Div(
                    HTML(
                        f"""
                        <p>Install antares2goats from browser extension store:</p>
                        <a href="{chrome_extension_url}" target="_blank">
                        <img src="{chrome_img_url}" alt="Chrome Extension Store" class="img-fluid"
                        style="display: inline-block; max-height: 50px;"></a>
                        <a href="{firefox_extension_url}" target="_blank">
                        <img src="{firefox_img_url}" alt="Firefox Extension Store" class="img-fluid"
                        style="display: inline-block; max-height: 50px;"></a>
                        <p>Configure extension by providing an API token generated by your Admin.</p>
                    """,
                    ),
                    css_class="col-md-12",
                ),
                css_class="row g-3",
            ),
            HTML("<hr>"),
            Div(
                Fieldset("Elastic Search Query", "query_name", "query"),
                HTML(
                    """
                    <p>
                    Please see <a href="https://noao.gitlab.io/antares/client/tutorial/searching.html">ANTARES
                    Documentation</a> for a detailed description of advanced searches.
                    </p>
                """,
                ),
                css_class="col",
            ),
        )
        # ruff: enable

    def clean(self):
        """Cleans the data of the "query" field and validates it.
        GG
                Returns
                -------
                dict
                    The cleaned data of the form.

                Raises
                ------
                forms.ValidationError
                    Raised if the "query" field is empty.

        """
        cleaned_data = super().clean()
        if not cleaned_data.get("query"):
            raise forms.ValidationError("Invalid entry for Elastic Search query form.")

        return cleaned_data


class ANTARESBroker(GenericBroker):
    """Extends the ANTARESBroker.

    Attributes
    ----------
    form : GOATSANTARESBrokerForm
        The form class to be used within the broker.

    """

    name = "ANTARES"
    form = ANTARESBrokerForm

    @classmethod
    def alert_to_dict(cls, locus) -> dict[str, Any]:
        """Serializes a Locus object into a dictionary for caching in the view.

        Parameters
        ----------
        locus : Locus
            The Locus object returned by the ANTARES API.

        Returns
        -------
        dict
            A dictionary representation of the Locus object.
        """
        return {
            "locus_id": locus.locus_id,
            "ra": locus.ra,
            "dec": locus.dec,
            "properties": locus.properties,
            "tags": locus.tags,
            "lightcurve": locus.lightcurve,
            "catalogs": locus.catalogs,
            "alerts": [
                {
                    "alert_id": alert.alert_id,
                    "mjd": alert.mjd,
                    "properties": alert.properties,
                }
                for alert in locus.alerts
            ],
        }

    def fetch_alerts(self, parameters: dict[str, Any]) -> Iterator[dict[str, Any]]:
        """Fetches alerts based on user input.

        Parameters
        ----------
        parameters : dict[str, Any]
            Query parameters containing either a query string or a locus ID.

        Returns
        -------
        Iterator[dict[str, Any]]
            An iterator of alert dictionaries.
        """
        query = parameters.get("query")
        locusid = parameters.get("locusid")
        max_alerts = 40
        alerts = []

        if locusid:
            # Fetch alert by locus ID.
            locus = get_by_id(locusid)
            alerts.append(self.alert_to_dict(locus))

        elif query:
            # Set query parameter.
            # Initiate search with the given query.
            loci = search(query)

            while len(alerts) < max_alerts:
                try:
                    locus = next(loci)
                except (marshmallow.exceptions.ValidationError, StopIteration):
                    # Break the loop if there is a validation error or no more items in
                    # the iterator.
                    break
                alerts.append(self.alert_to_dict(locus))

        return iter(alerts)

    def to_target(
        self, alert: dict[str, Any]
    ) -> tuple[BaseTarget, dict, list[TargetName]]:
        """Converts an alert dictionary into a Target object and associated aliases.

        Parameters
        ----------
        alert : dict[str, Any]
            The alert data containing target details.

        Returns
        -------
        tuple[BaseTarget, dict, list[TargetName]]
            A tuple containing the created `BaseTarget`, an empty dictionary, and a list of aliases.
        """
        name = alert["locus_id"]
        target = Target.objects.create(
            name=name,
            type="SIDEREAL",
            ra=alert["ra"],
            dec=alert["dec"],
        )
        aliases = self.extract_survey_aliases(target, alert)

        return target, {}, aliases

    def to_generic_alert(self, alert: dict[str, Any]) -> GenericAlert:
        """Converts an alert dictionary into a `GenericAlert` object.

        Parameters
        ----------
        alert : dict[str, Any]
            The alert data to be converted.

        Returns
        -------
        GenericAlert
            The corresponding GenericAlert object.
        """
        # FIXME: Currently only recording the name as the locus ID.
        # name = alert["properties"]["ztf_object_id"]
        name = alert["locus_id"]
        url = f"{ANTARESConfig.get_url()}/loci/{name}"
        timestamp = Time(
            alert["properties"].get("newest_alert_observation_time"),
            format="mjd",
            scale="utc",
        ).to_datetime(timezone=TimezoneInfo())

        return GenericAlert(
            timestamp=timestamp,
            url=url,
            id=name,
            name=name,
            ra=alert["ra"],
            dec=alert["dec"],
            mag=alert["properties"].get("newest_alert_magnitude", ""),
            score=alert["alerts"][-1]["properties"].get("ztf_rb", ""),
        )

    def extract_survey_aliases(
        self, target: BaseTarget, alert: dict[str, Any]
    ) -> list[TargetName]:
        """Extracts survey-specific aliases from the alert data.

        Parameters
        ----------
        target : BaseTarget
            The target associated with the alert.
        alert : dict[str, Any]
            The alert data containing potential survey aliases.

        Returns
        -------
        list[TargetName]
            A list of TargetName objects representing the survey aliases.
        """
        logger.debug("Extracting survey aliases for target: %s", target.name)
        aliases: list[TargetName] = []
        # A set to track seen alias values to avoid duplicates.
        seen: set[str] = set()

        properties = alert.get("properties") or {}
        survey = properties.get("survey") or {}

        def add_aliases(values: list[str] | None) -> None:
            """
            Adds aliases to the list from the provided values.

            Parameters
            ----------
            values : list[str] | None
                A list of alias values to be added.
            """
            if not values:
                return
            for value in values:
                if not value or value in seen:
                    continue
                seen.add(value)
                logger.debug("Adding alias: %s", value)
                aliases.append(TargetName(target=target, name=value))

        # Get Horizons alias.
        horizons_name = properties.get("horizons_targetname")
        if horizons_name:
            add_aliases([horizons_name])

        # Get ZTF aliases.
        ztf = survey.get("ztf") or {}
        add_aliases(ztf.get("id"))

        # Get LSST aliases.
        lsst = survey.get("lsst") or {}
        add_aliases(lsst.get("dia_object_id"))
        add_aliases(lsst.get("ss_object_id"))

        return aliases

    def process_lightcurve_data(self, alert=None):
        """
        Normalize and transform ANTARES lightcurve data into a standardized DataFrame.

        Parameters
        ----------
        alert : dict, optional
            Alert payload returned by the ANTARES broker. Expected to contain
            a "lightcurve" key and optionally "properties.survey".

        Returns
        -------
        pandas.DataFrame or None
            Processed lightcurve DataFrame with standardized columns:
            - time
            - magnitude
            - error
            - limit
            - filter
            - telescope
            - source

            Returns None if the lightcurve is missing, invalid, or empty.
        """
        alert_dict = alert or {}
        lightcurve = alert_dict.get("lightcurve")

        if lightcurve is None:
            return

        if not isinstance(lightcurve, pd.DataFrame):
            try:
                lightcurve = pd.DataFrame(lightcurve)
            except Exception:
                logger.exception("ANTARES: failed to convert lightcurve to DataFrame")
                return

        if lightcurve.empty:
            return

        lightcurve = lightcurve.drop(columns=["time", "ant_survey"], errors="ignore")

        lightcurve = lightcurve.rename(
            columns={
                "ant_mjd": "time",
                "ant_mag": "magnitude",
                "ant_magerr": "error",
                "ant_maglim": "limit",
                "ant_passband": "filter",
            }
        )

        try:
            survey = alert_dict.get("properties", {}).get("survey", {})
            telescope = list(survey.keys())[0].upper()
            lightcurve["telescope"] = telescope
        except Exception:
            logger.exception("ANTARES: failed to extract telescope")
            lightcurve["telescope"] = "UNKNOWN"

        lightcurve["source"] = "ANTARES"

        return lightcurve

    def create_lightcurve_dp(self, target, lightcurve):
        """
        Create or update a photometry DataProduct for a target.

        This method ensures idempotent behavior:
        - If a DataProduct with the same product_id exists, it updates the file.
        - Otherwise, it creates a new DataProduct.

        Parameters
        ----------
        target : tom_targets.models.Target
            Target associated with the lightcurve.
        lightcurve : pandas.DataFrame
            Processed lightcurve data.

        Returns
        -------
        tom_dataproducts.models.DataProduct
            The created or updated DataProduct instance.
        """
        csv_string = lightcurve.to_csv(index=False)

        product_id = f"{target.name}_lightcurve"
        file_name = f"{target.name}_lightcurve.csv"
        data = ContentFile(csv_string.encode("utf-8"), name=file_name)

        try:
            with transaction.atomic():
                dp, created = DataProduct.objects.get_or_create(
                    product_id=product_id,
                    defaults={
                        "target": target,
                        "data_product_type": "photometry",
                    },
                )
        except IntegrityError:
            dp = DataProduct.objects.get(product_id=product_id)

        dp.data.save(file_name, data, save=True)
        return dp

    def create_reduced_datums(self, dp):
        """
        Generate ReducedDatum entries from a photometry DataProduct.

        This method runs the TOM data processor on the provided DataProduct.
        If processing fails, it removes any partially created ReducedDatum
        entries and deletes the DataProduct to maintain database consistency.

        Parameters
        ----------
        dp : tom_dataproducts.models.DataProduct
            DataProduct containing the photometry file.

        Raises
        ------
        InvalidFileFormatException
            If the file format is invalid for processing.
        Exception
            For any unexpected processing error.
        """
        try:
            run_data_processor(dp)

        except InvalidFileFormatException:
            logger.exception("ANTARES: invalid file format dp_id=%s", dp.id)
            ReducedDatum.objects.filter(data_product=dp).delete()
            dp.delete()
            raise

        except Exception:
            logger.exception("ANTARES: unexpected error processing dp_id=%s", dp.id)
            ReducedDatum.objects.filter(data_product=dp).delete()
            dp.delete()
            raise
