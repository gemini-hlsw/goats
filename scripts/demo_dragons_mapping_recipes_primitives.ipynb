{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d368cfd1-c39c-4179-a11d-0dbd5ac91a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Monika Soraisam'\n",
    "__email__ = 'monika.soraisam@noirlab.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b186d-5cc3-4228-b331-c1a600deb0c5",
   "metadata": {},
   "source": [
    "## Refer here for more details https://dragons.readthedocs.io/projects/recipe-system-prog-manual/en/v3.2.0/intro.html\n",
    "\n",
    "\n",
    "\n",
    "## TAKEAWAY:\n",
    "- the `recipe_system.reduction.coreReduce.Reduce` is already robust and will be able to handle customized recipes sent from the GOATS frontend.\n",
    "- we DO NOT need to figure out the python class of the instrument and its mode to use<br>\n",
    "e.g., suppose the observation ID to be reduced is that from GMOS instrument in imaging mode. In one of the earlier notebooks I wrote  (*demo_dragons_reduction_gmos_imaging_spectrosocpy.ipynb*), for recipe customization I used to create an instance `p = gmos.primitives_gmos_image.GMOSImage(adin)`, which was then passed on as an argument to the customized recipe function, i.e., `customized_recipe_blah(p)`. I found that this is inadequate; in particular, we will need to always figure out the isntrument beforehand and the default parameters may not be rightly reflected when instantiating this way.\n",
    "\n",
    "  Turns out it's much simpler. All of these things will be correctly handled by `recipe_system.reduction.coreReduce.Reduce`; it will automatically also figure out the intrument class.  \n",
    "\n",
    "Go through this notebook to undertsand the primitive and recipe mapping. Lastly, main details for using `recipe_system.reduction.coreReduce.Reduce` with recipe customization are consolidated in [\"Everything handled by Reduce class\" block at the bottom of notebook](#blah). \n",
    "\n",
    "\n",
    "## Update: 2024-07-03 \n",
    "Apparently, one cannot simply pass the function name (the callable) to `Reduce` as it takes only a string as argument for recipename. On the otherhand, if the new recipe is not in the DRAGONS codebase, it crashes. One way to go about then is to use the `RecipeMapper` and `PrimitiveMapper` classes. But the more elegant way is to still use the `Reduce` class. Dan figured out that the argument needed to pass to the recipename is actually the module name. So, in other words, the customized recipe needs to be first converted into a module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d36363-dc86-4e83-b572-3bb72df31aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "# for bokeh apps to load from the jupyter notebook on a different browser tab\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce6153f-36c4-481a-bc57-205fc0fa3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the DRAGONS libraries \n",
    "import astrodata\n",
    "import gemini_instruments\n",
    "\n",
    "from gempy.scripts import showpars\n",
    "from gempy.utils.showrecipes import showrecipes\n",
    "from gempy.utils.showrecipes import showprims\n",
    "\n",
    "from recipe_system.mappers.primitiveMapper import PrimitiveMapper\n",
    "from recipe_system.mappers.recipeMapper import RecipeMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9249d408-fb8e-461b-a3e2-a1b16ae815cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_system.reduction.coreReduce import Reduce\n",
    "from recipe_system import cal_service\n",
    "from gempy.adlibrary import dataselect\n",
    "from gempy.utils import logutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc8c250-1708-4a3e-800c-e352785d14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep the reduction folder\n",
    "def prep_reduction_folder(data_root, obsid):\n",
    "    reduction_path = Path(f\"{data_root}/{obsid}/reduction\")\n",
    "\n",
    "    if not reduction_path.exists():\n",
    "        os.mkdir(reduction_path.as_posix())\n",
    "        print (f\"directory for dragons reduction created\")\n",
    "    \n",
    "    ## change the cwd to the reduction folder\n",
    "    os.chdir(reduction_path.as_posix())\n",
    "    print(f\"Current working directory is: {os.getcwd()}\")\n",
    "\n",
    "    ## write the configuration file \n",
    "    mydb = \"dragons_for_goats.db\" \n",
    "    mydb_path = reduction_path.as_posix() + '/' + mydb\n",
    "    print (mydb_path)\n",
    "    \n",
    "    dragons_rc = reduction_path.as_posix() + '/dragonsrc'\n",
    "    print (dragons_rc)\n",
    "    \n",
    "    with open(dragons_rc, \"w\") as f:\n",
    "        f.write(\"[calibs]\\ndatabases = {0} get store\".format(mydb_path))\n",
    "\n",
    "    return dragons_rc, mydb_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ab82d-c693-48e5-868b-26ef004d0393",
   "metadata": {},
   "source": [
    "# GMOS longslit example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ea5d3e-ff06-465c-8d50-8a93685ac3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is: /Users/monika.soraisam/Desktop/tomdev/real_goats/goats_data/ZTF18aabfthf/GEM/GS-2021A-DD-102-9/reduction\n",
      "/Users/monika.soraisam/Desktop/tomdev/real_goats/goats_data/ZTF18aabfthf/GEM/GS-2021A-DD-102-9/reduction/dragons_for_goats.db\n",
      "/Users/monika.soraisam/Desktop/tomdev/real_goats/goats_data/ZTF18aabfthf/GEM/GS-2021A-DD-102-9/reduction/dragonsrc\n"
     ]
    }
   ],
   "source": [
    "#data_path = \"/data/goats_dev_data/example_data/data/ZTF18acppavh/GEM\" ## linux machine \n",
    "data_path = \"/Users/monika.soraisam/Desktop/tomdev/real_goats/goats_data/ZTF18aabfthf/GEM\" ## mac \n",
    "obsid = 'GS-2021A-DD-102-9'\n",
    "dragons_rc, mydb_path = prep_reduction_folder(data_path, obsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ddb6ce-8d24-4202-a845-33e37b7341be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the calibration database and complete the set-up \n",
    "caldb = cal_service.LocalDB(mydb_path, force_init=True) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f05f7a-9aa4-4171-9a60-1874e07e6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "logutils.config(file_name='gmos_data_reduction.log') # logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ddbd9-f124-47e1-9dc3-5027dc437fe7",
   "metadata": {},
   "source": [
    "### Generate filelist for the data reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e513307a-3e6e-4940-ae8d-f842b45b71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filelists(location, obsid):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    location: str\n",
    "        Root folder where the Gemini data for a given target is located\n",
    "    obsid: str\n",
    "        Gemini observation ID \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    all_files = [str(pp) for pp in list(Path(location+\"/\"+obsid).glob('*.fits'))]\n",
    "    all_files.sort()\n",
    "    print (f'The total number of files for observation ID {obsid} is {len(all_files)}')\n",
    "\n",
    "    cal_file_tags = ['BIAS','DARK','FLAT','ARC','PINHOLE','RONCHI','FRINGE'] #fetched from Obs Type search field on GOA, which is relevant for DRAGONS\n",
    "\n",
    "    meta_keys = cal_file_tags + ['BPM','standard','object','unknown']\n",
    "    all_meta = {}\n",
    "\n",
    "    for K in meta_keys:\n",
    "        all_meta[K] = {'file':[],\n",
    "                        'group_id':[],\n",
    "                        'exp':[],\n",
    "                        'objname':[],\n",
    "                        'wave':[],\n",
    "                        'waveband':[],\n",
    "                        'date':[],\n",
    "                        'roi':[],\n",
    "                        }\n",
    "\n",
    "    object_files = []\n",
    "    for i,F in enumerate(all_files):\n",
    "        ad = astrodata.open(F)\n",
    "\n",
    "        K = \"unknown\"\n",
    "        if \"BPM\" in ad.tags:\n",
    "            K = \"BPM\"\n",
    "        elif \"PREPARED\" in ad.tags:\n",
    "            continue\n",
    "        elif (\"STANDARD\" in ad.tags or ad.observation_class()==\"partnerCal\" or ad.observation_class()==\"progCal\") and (\"UNPREPARED\" in ad.tags) and (ad.observation_type()==\"OBJECT\"):\n",
    "            K = \"standard\"            \n",
    "        elif \"CAL\" in ad.tags and \"UNPREPARED\" in ad.tags:\n",
    "            for tag in cal_file_tags:\n",
    "                if tag in ad.tags:\n",
    "                    K = tag\n",
    "        elif ad.observation_class()==\"science\" and \"UNPREPARED\" in ad.tags:\n",
    "            K = \"object\"\n",
    "            \n",
    "        all_meta[K]['file'].append(F)\n",
    "        # group_id seems to be not implemented for GNIRS yet\n",
    "        if \"GNIRS\" in ad.instrument():\n",
    "            all_meta[K]['group_id'].append(None)\n",
    "        else:\n",
    "            all_meta[K]['group_id'].append(ad.group_id())\n",
    "        all_meta[K]['exp'].append(ad.exposure_time())\n",
    "        all_meta[K]['objname'].append(ad.object())\n",
    "        all_meta[K]['wave'].append(ad.central_wavelength())\n",
    "        all_meta[K]['waveband'].append(ad.wavelength_band())\n",
    "        all_meta[K]['date'].append(ad.ut_date())\n",
    "        all_meta[K]['roi'].append(ad.detector_roi_setting()) \n",
    "        #print (F.split('/')[-1], ad.object(), ad.tags)\n",
    "    \n",
    "    return all_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c76241-a601-4bb1-bc33-032ae9177951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of files for observation ID GS-2021A-DD-102-9 is 58\n",
      "There are 50 files for observation type BIAS\n",
      "There are 2 files for observation type FLAT\n",
      "There are 2 files for observation type ARC\n",
      "There are 3 files for observation type object\n",
      "There are 1 files for observation type unknown\n"
     ]
    }
   ],
   "source": [
    "all_meta = generate_filelists(data_path, obsid)\n",
    "\n",
    "for K,V in all_meta.items():\n",
    "    if len(V['file'])==0:\n",
    "        continue\n",
    "    print (f\"There are {len(V['file'])} files for observation type {K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5065a92e-43af-4519-adfd-8e3dd0003443",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_bias = pd.DataFrame(all_meta['BIAS'])\n",
    "DF_flat = pd.DataFrame(all_meta['FLAT'])\n",
    "#DF_bpm = pd.DataFrame(all_meta['BPM'])\n",
    "DF_arc = pd.DataFrame(all_meta['ARC'])\n",
    "DF_object = pd.DataFrame(all_meta['object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc93bd51-0f55-4599-922f-e79fbe85a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add BPM to the calibration database (the BPM is already processed)\n",
    "for F in caldb.list_files():\n",
    "    print (F)\n",
    "\n",
    "# for F in DF_bpm['file'].values:\n",
    "#     caldb.add_cal(F)\n",
    "\n",
    "for F in caldb.list_files():\n",
    "    print (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b202d-de12-49ed-844e-601f06824d0a",
   "metadata": {},
   "source": [
    "## For each group of files, below one can see how it could be mapped to the appropriate/default recipe and primitives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07f5a11-d0e2-41c4-bfd1-9b27cd0e2fa4",
   "metadata": {},
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c80a6c58-dc85-4091-be26-d54b8f7b9a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>group_id</th>\n",
       "      <th>exp</th>\n",
       "      <th>objname</th>\n",
       "      <th>wave</th>\n",
       "      <th>waveband</th>\n",
       "      <th>date</th>\n",
       "      <th>roi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/goats_dev_data/example_data/data/ZTF18ac...</td>\n",
       "      <td>2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>6.750000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Full Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/goats_dev_data/example_data/data/ZTF18ac...</td>\n",
       "      <td>2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>6.750000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Full Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/goats_dev_data/example_data/data/ZTF18ac...</td>\n",
       "      <td>2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>6.750000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Full Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/goats_dev_data/example_data/data/ZTF18ac...</td>\n",
       "      <td>2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>6.750000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Full Frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/goats_dev_data/example_data/data/ZTF18ac...</td>\n",
       "      <td>2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bias</td>\n",
       "      <td>6.750000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Full Frame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  /data/goats_dev_data/example_data/data/ZTF18ac...   \n",
       "1  /data/goats_dev_data/example_data/data/ZTF18ac...   \n",
       "2  /data/goats_dev_data/example_data/data/ZTF18ac...   \n",
       "3  /data/goats_dev_data/example_data/data/ZTF18ac...   \n",
       "4  /data/goats_dev_data/example_data/data/ZTF18ac...   \n",
       "\n",
       "                                            group_id  exp objname  \\\n",
       "0  2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...  0.0    Bias   \n",
       "1  2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...  0.0    Bias   \n",
       "2  2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...  0.0    Bias   \n",
       "3  2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...  0.0    Bias   \n",
       "4  2_2_Normal_[\"'BI5-36-4k-2, 4':[1:512,1:4224]\",...  0.0    Bias   \n",
       "\n",
       "           wave waveband        date         roi  \n",
       "0  6.750000e-07     None  2021-02-11  Full Frame  \n",
       "1  6.750000e-07     None  2021-02-11  Full Frame  \n",
       "2  6.750000e-07     None  2021-02-11  Full Frame  \n",
       "3  6.750000e-07     None  2021-02-11  Full Frame  \n",
       "4  6.750000e-07     None  2021-02-11  Full Frame  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's look at the flat group\n",
    "DF_bias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cfc0867-fe69-4c0f-adca-fb7e4120edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = astrodata.open(DF_bias['file'].values[0]) ## just take any file from the group; I'm taking the first file. The purpose is to get the corresponding tags of the group\n",
    "tags = ad.tags\n",
    "instpkg = ad.instrument(generic=True).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eeceb6f-bc08-4e6a-8a04-aa44a4fbe1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the tags and instrument package name are used as arguments to the mappers\n",
    "\n",
    "rmapper = RecipeMapper(tags, instpkg) # recipe mapper \n",
    "pmapper = PrimitiveMapper(tags, instpkg) # primitive mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2dc8c3-f8fe-45cf-abf0-cdc425b614f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"a10595e7-b4f3-40de-94a5-66357e605984\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"88d58aef-6e7b-4cec-bf23-af39dead757e\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"89812f3b46fd41d4860b3659c59e1408\",\"client_comm_id\":\"7cfea49df88b486cafc653bf875c9b1c\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"88d58aef-6e7b-4cec-bf23-af39dead757e\",\"roots\":{\"p1002\":\"a10595e7-b4f3-40de-94a5-66357e605984\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## now get the applicable recipe and primitives corresponding to the tags and instrument package\n",
    "\n",
    "pclass = pmapper.get_applicable_primitives() \n",
    "recipe = rmapper.get_applicable_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e628b3-0c6e-49bc-920e-926df46ee090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geminidr.gmos.primitives_gmos.GMOS"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23285d6f-320a-44af-a069-6ec71ee74096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function geminidr.gmos.recipes.sq.recipes_BIAS.makeProcessedBias(p)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57761854-33f7-4a68-9033-f48d9682191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def makeProcessedBias(p):\n",
      "    \"\"\"\n",
      "     This recipe performs the standardization and corrections needed to convert\n",
      "     the raw input bias images into a single stacked bias image. This output\n",
      "     processed bias is stored on disk using storeProcessedBias and has a name\n",
      "     equal to the name of the first input bias image with \"_bias.fits\" appended.\n",
      "\n",
      "     Parameters\n",
      "     ----------\n",
      "     p : PrimitivesBASE object\n",
      "         A primitive set matching the recipe_tags.\n",
      "     \"\"\"\n",
      "\n",
      "    p.prepare()\n",
      "    p.addDQ(add_illum_mask=False)\n",
      "    p.addVAR(read_noise=True)\n",
      "    p.overscanCorrect()\n",
      "    p.stackBiases()\n",
      "    p.makeIRAFCompatible()\n",
      "    p.storeProcessedBias()\n",
      "    return\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let's examine the sequence of primitives in the recipe \n",
    "print(inspect.getsource(recipe.__code__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0f683-cbc1-43a2-988a-9cb57a22c7c2",
   "metadata": {},
   "source": [
    "**Note that the default recipe is chosen with the recipeMapper. If one were to see all possible recipes for a given group of files, then one will instead have to use gempy.utils.showrecipes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e324763d-732a-4b14-a837-bbb3fe57eefe",
   "metadata": {},
   "source": [
    "**Now instantiate the `pclass` with a list of astrodata objects of the corresponding input files** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d6e848-deb2-4b1e-b5ae-c6f6f1a76bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_input_list = []\n",
    "\n",
    "for F in DF_bias['file'].values:\n",
    "    ad_input_list.append(astrodata.open(F))\n",
    "\n",
    "len(ad_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f5cb04b-72c8-482d-a771-87726ef50df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mpclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madinputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sq'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mucals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muparms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mupload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconfig_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "This is the class containing all of the preprocessing primitives\n",
       "for the GMOS level of the type hierarchy tree. It inherits all\n",
       "the primitives from the level above\n",
       "\u001b[0;31mFile:\u001b[0m           /home/msoraisam/mambaforge/envs/goats-env/lib/python3.10/site-packages/geminidr/gmos/primitives_gmos.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     GMOSSpect, GMOSNodAndShuffle, GMOSImage"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pclass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98ff99a6-94f6-4eea-b19c-dd179e522922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an instance of the applicable primitive set\n",
    "p = pclass(ad_input_list, config_file=dragons_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617cd2e-4934-42b3-aa7e-26a32485cb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## let's see all the primitives/methods in this primitive set\n",
    "\n",
    "for item in dir(p):\n",
    "   if not item.startswith('_') and inspect.ismethod(getattr(p, item)):\n",
    "       print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9dd25-8d08-44c9-9f5a-8335af72dfca",
   "metadata": {},
   "source": [
    "**When one calls a recipe, it's just executing SEQUENTIALLY some number of the above instantiated primitive set methods** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91562952-5cdb-4ef7-a517-597078bfa9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recipe(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea58f26-9af7-4240-b159-30539165c8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8a7462-a10e-4fe4-b7bb-9559cd13f1b1",
   "metadata": {},
   "source": [
    "#\n",
    "### Flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "296f2a99-5095-403c-b70a-a235c5ba6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmos\n"
     ]
    }
   ],
   "source": [
    "ad = astrodata.open(DF_flat['file'].values[0]) \n",
    "tags = ad.tags\n",
    "instpkg = ad.instrument(generic=True).lower()\n",
    "print (instpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a09b09-27b8-4eb2-beb9-f4e272a30b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.2.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.2.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"b2888da9-d898-4ed9-a8f1-8ba98516aaa0\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"68f70a16-ac37-4fe7-ac46-2c99430128c4\":{\"version\":\"3.4.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"d30ccc2f6de846ada6165434ee25742d\",\"client_comm_id\":\"90738c3594c24e83aec3604e5d0efa38\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"68f70a16-ac37-4fe7-ac46-2c99430128c4\",\"roots\":{\"p1002\":\"b2888da9-d898-4ed9-a8f1-8ba98516aaa0\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmapper = RecipeMapper(tags, instpkg) # recipe mapper \n",
    "pmapper = PrimitiveMapper(tags, instpkg) # primitive mapper\n",
    "\n",
    "\n",
    "recipe = rmapper.get_applicable_recipe()\n",
    "pclass = pmapper.get_applicable_primitives() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aeb6f98-2d86-4e7f-9421-7b1c892c895f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function geminidr.gmos.recipes.sq.recipes_FLAT_LS_SPECT.makeProcessedFlatNoStack(p)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da5fec3-51f2-4609-b988-74f45102d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geminidr.gmos.primitives_gmos_longslit.GMOSLongslit"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18f5d399-20b3-4e02-9e6d-95e3bfa0dbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_input_list = []\n",
    "\n",
    "for F in DF_flat['file'].values:\n",
    "    ad_input_list.append(astrodata.open(F))\n",
    "\n",
    "len(ad_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370e1021-4417-4ee9-8287-459888636361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an instance of the applicable primitive set\n",
    "p = pclass(ad_input_list, config_file=dragons_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c358399a-1e0f-4c59-a0e7-8d7026b676cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ADUToElectrons\n",
      "\n",
      "        This primitive will convert the units of the pixel data extensions\n",
      "        of the input AstroData object from ADU to electrons by multiplying\n",
      "        by the gain. The gain keyword in each extension is then set to 1.0\n",
      "        to represent the new conversion factor.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str/None\n",
      "            suffix to be added to output filenames\n",
      "        \n",
      "\n",
      "\n",
      "QECorrect\n",
      "\n",
      "        This primitive applies a wavelength-dependent QE correction to\n",
      "        a 2D spectral image, based on the wavelength solution in the WCS\n",
      "        (from `attachWavelengthSolution` or, in non-SQ-modes, the initial\n",
      "        linear approximation).\n",
      "\n",
      "        It is only designed to work on FLATs, and therefore unmosaicked data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "addDQ\n",
      "\n",
      "        This primitive is used to add a DQ extension to the input AstroData\n",
      "        object. The value of a pixel in the DQ extension will be the sum of the\n",
      "        following: (0=good, 1=bad pixel (found in bad pixel mask), 2=pixel is\n",
      "        in the non-linear regime, 4=pixel is saturated). This primitive will\n",
      "        trim the BPM to match the input AstroData object(s).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        static_bpm: str\n",
      "            Name of bad pixel mask (\"default\" -> use default from look-up table)\n",
      "            If set to None, no static_bpm will be added.\n",
      "        user_bpm: str\n",
      "            Name of the bad pixel mask created by the user from flats and\n",
      "            darks.  It is an optional BPM that can be added to the static one.\n",
      "        add_illum_mask: bool\n",
      "            add illumination mask?\n",
      "        \n",
      "\n",
      "\n",
      "addIllumMaskToDQ\n",
      "\n",
      "        Adds an illumination mask to each AD object. This is only done for\n",
      "        full-frame (not Central Spectrum) GMOS spectra, and is calculated by\n",
      "        making a model illumination patter from the attached MDF and cross-\n",
      "        correlating it with the spatial profile of the data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str\n",
      "            suffix to be added to output files\n",
      "        illum_mask : str/None\n",
      "            name of illumination mask mask (None -> use default)\n",
      "        shift : int/None\n",
      "            user-defined shift to apply to illumination mask\n",
      "        max_shift : int\n",
      "            maximum shift (in unbinned pixels) allowable for the cross-\n",
      "            correlation\n",
      "        \n",
      "\n",
      "\n",
      "addMDF\n",
      "\n",
      "        This primitive is used to add an Mask Definition File (MDF) extension to\n",
      "        the input AstroData object. This MDF extension consists of a FITS binary\n",
      "        table with information about where the spectroscopy slits are in\n",
      "        the focal plane mask. In IFU, it is the position of the fibers. In\n",
      "        Multi-Object Spectroscopy, it is the position of the multiple slits.\n",
      "        In longslit is it the position of the single slit.\n",
      "\n",
      "        If only one MDF is provided, that MDF will be added to all input AstroData\n",
      "        object(s). If more than one MDF is provided, the number of MDF AstroData\n",
      "        objects must match the number of input AstroData objects.\n",
      "\n",
      "        If no MDF is provided, the primitive will attempt to determine an\n",
      "        appropriate MDF.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        mdf: str/None\n",
      "            name of MDF to add (None => use default)\n",
      "        \n",
      "\n",
      "\n",
      "addObjectMaskToDQ\n",
      "\n",
      "        Combines the object mask in a `OBJMASK` extension into the `DQ` (Data\n",
      "        Quality) plane.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : :class:`~astrodata.AstroData`\n",
      "            Images that contain `OBJMASK`. If `OBJMASK` does not exist, the\n",
      "            extension is untouched.\n",
      "\n",
      "        suffix: str/None\n",
      "            Suffix to be added to output filenames.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Images with updated `DQ` plane.\n",
      "        \n",
      "\n",
      "\n",
      "addToList\n",
      "\n",
      "        This primitive will update the lists of files to be stacked\n",
      "        that have the same observationID with the current inputs.\n",
      "        This file is cached between calls to reduce, thus allowing\n",
      "        for one-file-at-a-time processing.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        purpose: str (None => \"list\")\n",
      "            purpose/name of this list, used as suffix for files\n",
      "        \n",
      "\n",
      "\n",
      "addVAR\n",
      "\n",
      "        This primitive adds noise components to the VAR plane of each extension\n",
      "        of each input AstroData object (creating the VAR plane if necessary).\n",
      "        The calculations for these components are abstracted out to separate\n",
      "        methods that operate on an individual AD object in-place.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        read_noise: bool (optional, default: False)\n",
      "            add the read noise component?\n",
      "        poisson_noise: bool (optional, default: False)\n",
      "            add the Poisson noise component?\n",
      "        \n",
      "\n",
      "\n",
      "adjustWCSToReference\n",
      "\n",
      "        Compute offsets along the slit by cross-correlation, or use offset\n",
      "        from the headers (QOFFSET). The computed offset is stored in the\n",
      "        SLITOFF keyword.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Wavelength calibrated 1D or 2D spectra.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files\n",
      "        method : str ['correlation' | 'offsets']\n",
      "            Method to use to compute offsets. 'correlation' uses a\n",
      "            correlation of the slit profiles (the 2d images stacked\n",
      "            on the dispersion axis), 'offsets' uses the QOFFSET keyword.\n",
      "        region: str / None\n",
      "            pixel region for determining slit profile for cross-correlation\n",
      "        tolerance : float\n",
      "            Maximum distance from the header offset, for the correlation\n",
      "            method (arcsec). If the correlation computed offset is too\n",
      "            different from the header offset, then the latter is used.\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "adjustWavelengthZeroPoint\n",
      "\n",
      "        Find sky lines and match them to a linelist in order to shift the\n",
      "        wavelength scale zero point slightly to account for flexure in the\n",
      "        telescope.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Wavelength calibrated 2D spectra.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files\n",
      "        center : None or int\n",
      "            Central row/column for 1D extraction (None => use middle).\n",
      "        shift : float, Default : None\n",
      "            An optional shift to apply directly to the wavelength scale, in\n",
      "            pixels. If not given, the shift will be calculated from the sky\n",
      "            lines present in the image.\n",
      "        verbose : bool, Default : False\n",
      "            Print additional information on the fitting process.\n",
      "        \n",
      "\n",
      "\n",
      "appendStream\n",
      "\n",
      "        This primitive takes the AstroData objects in a stream and appends them\n",
      "        (order unchanged) to the end of the current stream. If requested, the\n",
      "        stream whose ADs are being appended is deleted.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        new_stream: str\n",
      "            name of stream whose ADs are going to be appended to the working\n",
      "            stream\n",
      "        copy: bool\n",
      "            append full deepcopies of the AD objects?\n",
      "        \n",
      "\n",
      "\n",
      "applyDQPlane\n",
      "\n",
      "        This primitive sets the value of pixels in the science plane according\n",
      "        to flags from the DQ plane. A uniform mean/median or specific value can\n",
      "        be given, or a ring filter can be used (if inner_radius and outer_radius\n",
      "        are both defined, and replace_value is *not* a number).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        replace_flags: int\n",
      "            The DQ bits, of which one needs to be set for a pixel to be replaced\n",
      "        replace_value: str/float\n",
      "            \"median\" or \"mean\" to replace with that value of the good pixels,\n",
      "            or a value\n",
      "        inner_radius: float/None\n",
      "            inner radius of the mean/median cleaning filter\n",
      "        outer_radius: float/None\n",
      "            outer radius of the cleaning filter\n",
      "        max_iters: int\n",
      "            maximum number of cleaning iterations to perform\n",
      "        \n",
      "\n",
      "\n",
      "associateSky\n",
      "\n",
      "        This primitive determines which sky AstroData objects are associated\n",
      "        with each science AstroData object and puts this information in a\n",
      "        Table attached to each science frame.\n",
      "\n",
      "        The input sky AstroData objects can be provided by the user using the\n",
      "        parameter 'sky'. Otherwise, the science AstroData objects are found in\n",
      "        the main stream (as normal) and the sky AstroData objects are found in\n",
      "        the sky stream.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        distance: float\n",
      "            minimum separation (in arcseconds) required to use an image as sky\n",
      "        max_skies: int/None\n",
      "            maximum number of skies to associate to each input frame\n",
      "        min_skies: int/None\n",
      "            minimum number of skies to associate to each input frame\n",
      "        sky: str/list\n",
      "            name(s) of sky frame(s) to associate to each input\n",
      "        time: float\n",
      "            number of seconds\n",
      "        use_all: bool\n",
      "            use all input frames as skies (unless they are too close on the sky)?\n",
      "        \n",
      "\n",
      "\n",
      "attachWavelengthSolution\n",
      "\n",
      "        Attach the distortion map (a Chebyshev2D model) and the mapping from\n",
      "        distortion-corrected pixels to wavelengths (a Chebyshev1D model, when\n",
      "        available after successful line matching) from a processed arc, or\n",
      "        similar wavelength reference, to the WCS of the input data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            2D spectral images.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        arc : :class:`~astrodata.AstroData` or str or None\n",
      "            Arc(s) containing distortion map & wavelength calibration.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Modified input objects with the WCS updated for each extension.\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "biasCorrect\n",
      "\n",
      "        The biasCorrect primitive will subtract the science extension of the\n",
      "        input bias frames from the science extension of the input science\n",
      "        frames. The variance and data quality extension will be updated, if\n",
      "        they exist. If no bias is provided, the calibration database(s) will\n",
      "        be queried.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        bias: str/list of str\n",
      "            bias(es) to subtract\n",
      "        do_cal: str\n",
      "            perform bias subtraction?\n",
      "        \n",
      "\n",
      "\n",
      "calculateSensitivity\n",
      "\n",
      "        Calculates the overall sensitivity of the observation system\n",
      "        (instrument, telescope, detector, etc) for each wavelength using\n",
      "        spectrophotometric data. It is obtained using the ratio\n",
      "        between the observed data and the reference look-up data.\n",
      "\n",
      "        For that, it looks for reference data using the stripped and lower\n",
      "        case name of the observed object inside :mod:`geminidr.gemini.lookups`,\n",
      "        :mod:`geminidr.core.lookups` and inside the instrument lookup module.\n",
      "\n",
      "        The reference data is fit using a Spline in order to match the input\n",
      "        data sampling.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        - :class:`~gempy.library.astromodels.UnivariateSplineWithOutlierRemoval`\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            1D spectra of spectrophotometric standard stars\n",
      "\n",
      "        suffix :  str, optional\n",
      "            Suffix to be added to output files (default: _sensitivityCalculated).\n",
      "\n",
      "        filename: str or None, optional\n",
      "            Location of spectrophotometric data file. If it is None, uses\n",
      "            look up data based on the object name stored in OBJECT header key\n",
      "            (default).\n",
      "\n",
      "        function : str\n",
      "            type of function to fit (splineN or polynomial types)\n",
      "\n",
      "        order : int\n",
      "            Order of the spline fit to be performed\n",
      "\n",
      "        lsigma, hsigma : float/None\n",
      "            lower and upper rejection limit in standard deviations\n",
      "\n",
      "        niter : int\n",
      "            maximum number of rejection iterations\n",
      "\n",
      "        bandpass : float, optional\n",
      "            default bandpass width (in nm) to use if not present in the\n",
      "            spectrophotometric data table (default: 5.)\n",
      "\n",
      "        resampling: float/None\n",
      "            if not None, resample the specphot file to this wavelength\n",
      "            interval (in nm) before calculating the sensitivity\n",
      "\n",
      "        interactive: bool, optional\n",
      "            Run the interactive UI for selecting the fit parameters\n",
      "\n",
      "        individual : bool - TODO - Not in calculateSensitivityConfig\n",
      "            Calculate sensitivity for each AD spectrum individually?\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The same input list is used as output but each object now has a\n",
      "            `.SENSFUNC` table appended to each of its extensions. This table\n",
      "            provides details of the fit which describes the sensitivity as\n",
      "            a function of wavelength.\n",
      "        \n",
      "\n",
      "\n",
      "checkWCS\n",
      "\n",
      "        This primitive checks for consistency within the WCS by comparing the\n",
      "        header offsets with the WCS coordinates\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        tolerance: float\n",
      "            positional tolerance in arcseconds\n",
      "        \n",
      "\n",
      "\n",
      "clearAllStreams\n",
      "\n",
      "        This primitive clears all streams (except \"main\") by setting them\n",
      "        to empty lists.\n",
      "        \n",
      "\n",
      "\n",
      "clearStream\n",
      "\n",
      "        This primitive clears a stream by returning an empty list, which the\n",
      "        decorator then pushes into the stream.\n",
      "        \n",
      "\n",
      "\n",
      "copyInputs\n",
      "\n",
      "        This primitive results in deepcopies of the AD objects in one stream\n",
      "        being placed in another stream. All the work is handled by the\n",
      "        decorator, using the instream/outstream keywords, which is why this\n",
      "        primitive appears to do nothing.\n",
      "        \n",
      "\n",
      "\n",
      "correctBackgroundToReference\n",
      "\n",
      "        This primitive does an additive correction to a set\n",
      "        of images to put their sky background at the same level\n",
      "        as the reference image before stacking.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        remove_background: bool\n",
      "            if True, set the new background level to zero in all images\n",
      "            if False, set it to the level of the first image\n",
      "        \n",
      "\n",
      "\n",
      "createNewAperture\n",
      "\n",
      "        Create a new aperture, as an offset from another (given) aperture.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            A list of spectra with an APERTURE table.\n",
      "        aperture : int\n",
      "            Aperture number upon which to base new aperture.\n",
      "        shift : float\n",
      "            Shift (in pixels) to new aperture.\n",
      "        aper_lower : float\n",
      "            Distance in pixels from center to lower edge of new aperture.\n",
      "        aper_upper : float\n",
      "            Distance in pixels from center to upper edge of new aperture.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The same input list is used as output but each object now has a new\n",
      "            aperture in its APERTURE table, created as an offset from an\n",
      "            existing aperture.\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "darkCorrect\n",
      "\n",
      "        This primitive will subtract each SCI extension of the inputs by those\n",
      "        of the corresponding dark. If the inputs contain VAR or DQ frames,\n",
      "        those will also be updated accordingly due to the subtraction on the\n",
      "        data. If no dark is provided, the calibration database(s) will be\n",
      "        queried.\n",
      "\n",
      "        For GMOS Hamamatsu CCDs, nod & shuffle darks are optional.\n",
      "        They are required for the other flavors of CCDs.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        dark: str/list\n",
      "            name(s) of the dark file(s) to be subtracted\n",
      "        do_dark: bool\n",
      "            perform dark correction?\n",
      "        \n",
      "\n",
      "\n",
      "determineDistortion\n",
      "\n",
      "        Maps the distortion on a detector by tracing lines perpendicular to the\n",
      "        dispersion direction. Then it fits a 2D Chebyshev polynomial to the\n",
      "        fitted coordinates in the dispersion direction. The distortion map does\n",
      "        not change the coordinates in the spatial direction.\n",
      "\n",
      "        The Chebyshev2D model is stored as part of a gWCS object in each\n",
      "        `nddata.wcs` attribute, which gets mapped to a FITS table extension\n",
      "        named `WCS` on disk.\n",
      "\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Arc data as 2D spectral images with the distortion and wavelength\n",
      "            solutions encoded in the WCS.\n",
      "\n",
      "        suffix :  str\n",
      "            Suffix to be added to output files.\n",
      "\n",
      "        spatial_order : int\n",
      "            Order of fit in spatial direction.\n",
      "\n",
      "        spectral_order : int\n",
      "            Order of fit in spectral direction.\n",
      "\n",
      "        id_only : bool\n",
      "            Trace using only those lines identified for wavelength calibration?\n",
      "\n",
      "        min_snr : float\n",
      "            Minimum signal-to-noise ratio for identifying lines (if\n",
      "            id_only=False).\n",
      "\n",
      "        nsum : int\n",
      "            Number of rows/columns to sum at each step.\n",
      "\n",
      "        step : int\n",
      "            Size of step in pixels when tracing.\n",
      "\n",
      "        max_shift : float\n",
      "            Maximum orthogonal shift (per pixel) for line-tracing (unbinned).\n",
      "\n",
      "        max_missed : int\n",
      "            Maximum number of steps to miss before a line is lost.\n",
      "\n",
      "        min_line_length: float\n",
      "            Minimum length of traced feature (as a fraction of the tracing dimension\n",
      "            length) to be considered as a useful line.\n",
      "\n",
      "        debug_reject_bad: bool\n",
      "            Reject lines with suspiciously high SNR (e.g. bad columns)? (Default: True)\n",
      "\n",
      "        debug: bool\n",
      "            plot arc line traces on image display window?\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The same input list is used as output but each object now has the\n",
      "            appropriate `nddata.wcs` defined for each of its extensions. This\n",
      "            provides details of the 2D Chebyshev fit which maps the distortion.\n",
      "        \n",
      "\n",
      "\n",
      "determineSlitEdges\n",
      "\n",
      "        Finds the edges of the illuminated regions of the CCD and stores the\n",
      "        Chebyshev polynomials used to fit them in a SLITEDGE table.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        spectral_order : int, Default : 3\n",
      "            Fitting order in the spectral direction (minimum of 1).\n",
      "        debug : bool, Default: False\n",
      "            Generate plots of several aspects of the fitting process.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images with a `SLITEDGE` table attached\n",
      "            to each extension.\n",
      "        \n",
      "\n",
      "\n",
      "determineWavelengthSolution\n",
      "\n",
      "        Determines the wavelength solution for an ARC and updates the wcs\n",
      "        with this solution. In addition, the solution and pixel/wavelength\n",
      "        matches are stored as an attached `WAVECAL` :class:`~astropy.table.Table`.\n",
      "\n",
      "        2D input images are converted to 1D by collapsing a slice of the image\n",
      "        along the dispersion direction, and peaks are identified. These are then\n",
      "        matched to an arc line list, using piecewise-fitting of (usually)\n",
      "        linear functions to match peaks to arc lines, using the\n",
      "        :class:`~gempy.library.matching.KDTreeFitter`.\n",
      "\n",
      "        The `.WAVECAL` table contains four columns:\n",
      "            [\"name\", \"coefficients\", \"peaks\", \"wavelengths\"]\n",
      "\n",
      "        The `name` and the `coefficients` columns contain information to\n",
      "        re-create an Chebyshev1D object, plus additional information about\n",
      "        the way the spectrum was collapsed. The `peaks` column contains the\n",
      "        (1-indexed) position of the lines that were matched to the catalogue,\n",
      "        and the `wavelengths` column contains the matched wavelengths.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "             Mosaicked Arc data as 2D spectral images or 1D spectra.\n",
      "\n",
      "        suffix : str/None\n",
      "            Suffix to be added to output files\n",
      "\n",
      "        order : int\n",
      "            Order of Chebyshev fitting function.\n",
      "\n",
      "        center : None or int\n",
      "            Central row/column for 1D extraction (None => use middle).\n",
      "\n",
      "        nsum : int, optional\n",
      "            Number of rows/columns to average.\n",
      "\n",
      "        combine_method: {\"mean\", \"median\"}\n",
      "            Method to use for combining rows/columns when extracting 1D-spectrum.\n",
      "            Default: \"mean\"\n",
      "        min_snr : float\n",
      "            Minimum S/N ratio in line peak to be used in fitting.\n",
      "\n",
      "        weighting : {'natural', 'relative', 'none'}\n",
      "            How to weight the detected peaks.\n",
      "\n",
      "        fwidth : float/None\n",
      "            Expected width of arc lines in pixels. It tells how far the\n",
      "            KDTreeFitter should look for when matching detected peaks with\n",
      "            reference arcs lines. If None, `fwidth` is determined using\n",
      "            `tracing.estimate_peak_width`.\n",
      "\n",
      "        min_sep : float\n",
      "            Minimum separation (in pixels) for peaks to be considered distinct\n",
      "\n",
      "        central_wavelength : float/None\n",
      "            central wavelength in nm (if None, use the WCS or descriptor)\n",
      "\n",
      "        dispersion : float/None\n",
      "            dispersion in nm/pixel (if None, use the WCS or descriptor)\n",
      "\n",
      "        linelist : str/None\n",
      "            Name of file containing arc lines. If None, then a default look-up\n",
      "            table will be used.\n",
      "\n",
      "        alternative_centers : bool\n",
      "            Identify alternative central wavelengths and try to fit them?\n",
      "\n",
      "        nbright : int (or may not exist in certain class methods)\n",
      "            Number of brightest lines to cull before fitting\n",
      "\n",
      "        absorption : bool\n",
      "            If feature type is absorption (default: \"False\")\n",
      "\n",
      "        interactive : bool\n",
      "            Use the interactive tool?\n",
      "\n",
      "        resolution: int/None\n",
      "            Resolution (as l/dl), to which to convolve ATRAN spectrum,\n",
      "            for ATRAN linelist and reference plot generation.\n",
      "            If None, the default value for the instrument/mode is used.\n",
      "\n",
      "        wv_band: {'20', '50', '80', '100', 'header'}\n",
      "            Water vapour content (as percentile) to be used for ATRAN model\n",
      "            selection. If \"header\", then the value from the header is used.\n",
      "\n",
      "        num_atran_lines: int/None\n",
      "            Maximum number of lines with largest weigths (within a wvl bin) to be\n",
      "            included in the generated ATRAN line list.\n",
      "\n",
      "        debug : bool\n",
      "            Enable plots for debugging.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Updated objects with a `.WAVECAL` attribute and improved wcs for\n",
      "            each slice\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        :class:`~geminidr.core.primitives_visualize.Visualize.mosaicDetectors`,\n",
      "        :class:`~gempy.library.matching.KDTreeFitter`,\n",
      "        \n",
      "\n",
      "\n",
      "dilateObjectMask\n",
      "\n",
      "        Grows the influence of objects detected by dilating the OBJMASK using\n",
      "        the binary_dilation routine\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        dilation: float\n",
      "            radius of dilation circle\n",
      "        repeat: bool\n",
      "            allow a repeated dilation? Unless set, the primitive will no-op\n",
      "            if the appropriate header keyword timestamp is found\n",
      "        \n",
      "\n",
      "\n",
      "display\n",
      "\n",
      "        Displays an image on the ds9 display, using multiple frames if\n",
      "        there are multiple extensions. Saturated pixels can be displayed\n",
      "        in red, and overlays can also be shown.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        extname: str\n",
      "            'SCI', 'VAR', or 'DQ': plane to display\n",
      "        frame: int\n",
      "            starting frame for display\n",
      "        ignore: bool\n",
      "            setting to True turns off the display\n",
      "        remove_bias: bool\n",
      "            attempt to subtract bias before displaying?\n",
      "        threshold: str='auto'/float\n",
      "            level above which to flag pixels as saturated\n",
      "        tile: bool\n",
      "            attempt to tile arrays before displaying?\n",
      "        zscale: bool\n",
      "            use zscale algorithm?\n",
      "        overlay: list\n",
      "            list of overlays for the display\n",
      "        \n",
      "\n",
      "\n",
      "distortionCorrect\n",
      "\n",
      "        Corrects optical distortion in science frames, using a distortion map\n",
      "        (a Chebyshev2D model, usually from a processed arc) that has previously\n",
      "        been attached to each input's WCS by attachWavelengthSolution.\n",
      "\n",
      "        If the input image requires mosaicking, then this is done as part of\n",
      "        the resampling, to ensure one, rather than two, interpolations.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            2D spectral images with appropriately-calibrated WCS.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        interpolant : str\n",
      "            Type of interpolant\n",
      "        subsample : int\n",
      "            Pixel subsampling factor.\n",
      "        dq_threshold : float\n",
      "            The fraction of a pixel's contribution from a DQ-flagged pixel to\n",
      "            be considered 'bad' and also flagged.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Modified input objects with distortion correct applied.\n",
      "        \n",
      "\n",
      "\n",
      "extractSpectra\n",
      "\n",
      "        Extracts one or more 1D spectra from a 2D spectral image, according to\n",
      "        the contents of the `.APERTURE` table.\n",
      "\n",
      "        If the `skyCorrectFromSlit()` primitive has not been performed, then a\n",
      "        1D sky spectrum is constructed from a nearby region of the image, and\n",
      "        subtracted from the source spectrum.\n",
      "\n",
      "        Each 1D spectrum is stored as a separate extension in a new AstroData\n",
      "        object with the wcs copied from the parent.\n",
      "\n",
      "        These new AD objects are placed in a separate stream from the\n",
      "        parent 2D images, which are returned in the default stream.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            2D spectral images with a `.APERTURE` table.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        method : {'standard', optimal', 'default'}\n",
      "            Extraction method.\n",
      "        width : float or None\n",
      "            Width of extraction aperture in pixels.\n",
      "        grow : float\n",
      "            Avoidance region around each source aperture if a sky aperture\n",
      "            is required. Default: 10.\n",
      "        subtract_sky : bool\n",
      "            Extract and subtract sky spectra from object spectra if the 2D\n",
      "            spectral image has not been sky subtracted?\n",
      "        debug: bool\n",
      "            draw apertures on image display window?\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Extracted spectra as 1D data.\n",
      "        \n",
      "\n",
      "\n",
      "findAcquisitionSlits\n",
      "\n",
      "        This primitive determines which rows of a 2D spectroscopic frame\n",
      "        contain the stars used for target acquisition, primarily so they can\n",
      "        be used later to estimate the image FWHM. This is done by cross-\n",
      "        correlating a vertical cut of the image with a cartoon model of the\n",
      "        slit locations determined from the MDF.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "findApertures\n",
      "\n",
      "        Finds sources in 2D spectral images and store them in an APERTURE table\n",
      "        for each extension. Each table will, then, be used in later primitives\n",
      "        to perform aperture extraction.\n",
      "\n",
      "        The primitive operates by first collapsing the 2D spectral image in\n",
      "        the spatial direction to identify sky lines as regions of high\n",
      "        pixel-to-pixel variance, and the regions between the sky lines which\n",
      "        consist of at least `min_sky_region` pixels are selected. These are\n",
      "        then collapsed in the dispersion direction to produce a 1D spatial\n",
      "        profile, from which sources are identified using a peak-finding\n",
      "        algorithm.\n",
      "\n",
      "        The widths of the apertures are determined by calculating a threshold\n",
      "        level relative to the peak, or an integrated flux relative to the total\n",
      "        between the minima on either side and determining where a smoothed\n",
      "        version of the source profile reaches this threshold.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        max_apertures : int\n",
      "            Maximum number of apertures expected to be found.\n",
      "        percentile : float (0 - 100) / None\n",
      "            percentile to use when collapsing along the dispersion direction\n",
      "            to obtain a slit profile / None => take mean\n",
      "        section : str\n",
      "            comma-separated list of colon-separated pixel coordinate pairs\n",
      "            indicating the region(s) over which the spectral signal should be\n",
      "            used. The first and last values can be blank, indicating to\n",
      "            continue to the end of the data\n",
      "        min_sky_region : int\n",
      "            minimum number of contiguous pixels between sky lines\n",
      "            for a region to be added to the spectrum before collapsing to 1D.\n",
      "        min_snr : float\n",
      "            minimum S/N ratio for detecting peaks\n",
      "        use_snr : bool\n",
      "            Convert data to SNR per pixel before collapsing and peak-finding?\n",
      "        threshold : float (0 - 1)\n",
      "            parameter describing either the height above background (relative\n",
      "            to peak) at which to define the edges of the aperture.\n",
      "        interactive : bool\n",
      "            Show interactive controls for fine tuning source aperture detection\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The 2D spectral images with APERTURE tables attached\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        :meth:`~geminidr.core.primitives_spect.Spect.determineDistortion`,\n",
      "        :meth:`~geminidr.cofe.primitives_spect.Spect.distortionCorrect`\n",
      "        \n",
      "\n",
      "\n",
      "fixPixels\n",
      "\n",
      "        This primitive replaces bad pixels by linear interpolation along\n",
      "        lines or columns using the nearest good pixels, similar to IRAF's\n",
      "        fixpix.\n",
      "\n",
      "        Regions must be specified either as a string, separated by semi-colons,\n",
      "        with the ``regions`` parameter, or with a file (``regions_file``), one\n",
      "        region per line.\n",
      "\n",
      "        Regions strings must be a comma-separated list of colon-separated\n",
      "        pixel coordinates or ranges, one per axis, in 1-indexed Cartesian\n",
      "        pixel co-ordinates, inclusive of the upper limit. Axes are specified\n",
      "        in Fortran order (reverse of the Python order). The extension can\n",
      "        be specified at the beginning of the string, separated from the\n",
      "        coordinates by a slash. If extension is not specified, the region\n",
      "        will be fixed for all extensions.\n",
      "\n",
      "        Examples::\n",
      "\n",
      "            450, 521 => single pixel, line 521, column 450\n",
      "            430:437, 513:533 => lines 513 to 533, columns 430 to 437\n",
      "            10:, 100 => line 100, columns 10 to the end\n",
      "            *, 100 => line 100\n",
      "            2/429:,100 => for extension 2 only\n",
      "\n",
      "        By default, interpolation is performed across the narrowest dimension\n",
      "        spanning bad pixels with interpolation along image lines if the two\n",
      "        dimensions are equal (in the 2D case). 3D is also supported with the\n",
      "        same behavior. For single pixels it is possible to use a local median\n",
      "        filter instead.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of `~astrodata.AstroData`\n",
      "            List of input files.\n",
      "        suffix : str\n",
      "            suffix to be added to output files.\n",
      "        regions : str\n",
      "            List of pixels or regions to fix (see description above).\n",
      "        regions_file : str\n",
      "            Path to a file containing the regions to fix. If both regions_file\n",
      "            and regions are supplied, both will be used and regions_file will\n",
      "            be used first.\n",
      "        axis : int  [None or 1 - 3]\n",
      "            Axis over which the interpolation is done, 1 is along the x-axis,\n",
      "            2 is along the y-axis, 3 is the z-axis.  If None (default), the\n",
      "            axis is determined from the narrowest dimension of each region.\n",
      "        use_local_median : bool\n",
      "            Use a local median filter for single pixels?\n",
      "        debug : bool\n",
      "            Display regions?\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "flagCosmicRays\n",
      "\n",
      "        Detect and clean cosmic rays in a 2D wavelength-dispersed image,\n",
      "        using the well-known LA Cosmic algorithm of van Dokkum (2001)*, as\n",
      "        implemented in McCully's optimized version for Python, \"astroscrappy\"+.\n",
      "\n",
      "        * LA Cosmic: http://www.astro.yale.edu/dokkum/lacosmic\n",
      "        + astroscrappy: https://github.com/astropy/astroscrappy\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "\n",
      "        spectral_order, spatial_order : int or None, optional\n",
      "            Order for fitting and subtracting object continuum and sky line\n",
      "            models, prior to running the main cosmic ray detection algorithm.\n",
      "            When None, defaults optimized for GMOS are used. To control which\n",
      "            fits are performed, use the bkgmodel parameter.\n",
      "\n",
      "       bkgmodel : {'both', 'object', 'skyline', 'none'}, optional\n",
      "           Set which background model(s) to use, between 'object', 'skyline',\n",
      "           'both', or 'none'. Different data may get better results with\n",
      "           different background models.\n",
      "           'both': Use both object and sky line models.\n",
      "           'object': Use object model only.\n",
      "           'skyline': Use sky line model only.\n",
      "           'none': Don't use a background model.\n",
      "           Default: 'skyline'.\n",
      "\n",
      "        bitmask : int, optional\n",
      "            Bits in the input data quality `flags` that are to be used to\n",
      "            exclude bad pixels from cosmic ray detection and cleaning. Default\n",
      "            65535 (all non-zero bits, up to 16 planes).\n",
      "\n",
      "        sigclip : float, optional\n",
      "            Laplacian-to-noise limit for cosmic ray detection. Lower values\n",
      "            will flag more pixels as cosmic rays. Default: 4.5.\n",
      "\n",
      "        sigfrac : float, optional\n",
      "            Fractional detection limit for neighboring pixels. For cosmic ray\n",
      "            neighbor pixels, a lapacian-to-noise detection limit of\n",
      "            sigfrac * sigclip will be used. Default: 0.3.\n",
      "\n",
      "        objlim : float, optional\n",
      "            Minimum contrast between Laplacian image and the fine structure\n",
      "            image.  Increase this value if cores of bright stars are flagged\n",
      "            as cosmic rays. Default: 5.0.\n",
      "\n",
      "        niter : int, optional\n",
      "            Number of iterations of the LA Cosmic algorithm to perform.\n",
      "            Default: 4.\n",
      "\n",
      "        sepmed : boolean, optional\n",
      "            Use the separable median filter instead of the full median filter.\n",
      "            The separable median is not identical to the full median filter,\n",
      "            but they are approximately the same and the separable median filter\n",
      "            is significantly faster and still detects cosmic rays well.\n",
      "            Default: True\n",
      "\n",
      "        cleantype : {'median', 'medmask', 'meanmask', 'idw'}, optional\n",
      "            Set which clean algorithm is used:\n",
      "            'median': An umasked 5x5 median filter\n",
      "            'medmask': A masked 5x5 median filter\n",
      "            'meanmask': A masked 5x5 mean filter\n",
      "            'idw': A masked 5x5 inverse distance weighted interpolation\n",
      "            Default: \"meanmask\".\n",
      "\n",
      "        fsmode : {'median', 'convolve'}, optional\n",
      "            Method to build the fine structure image:\n",
      "            'median': Use the median filter in the standard LA Cosmic algorithm\n",
      "            'convolve': Convolve the image with the psf kernel to calculate the\n",
      "            fine structure image.\n",
      "            Default: 'median'.\n",
      "\n",
      "        psfmodel : {'gauss', 'gaussx', 'gaussy', 'moffat'}, optional\n",
      "            Model to use to generate the psf kernel if fsmode == 'convolve' and\n",
      "            psfk is None. The current choices are Gaussian and Moffat profiles.\n",
      "            'gauss' and 'moffat' produce circular PSF kernels. The 'gaussx' and\n",
      "            'gaussy' produce Gaussian kernels in the x and y directions\n",
      "            respectively. Default: \"gauss\".\n",
      "\n",
      "        psffwhm : float, optional\n",
      "            Full Width Half Maximum of the PSF to use to generate the kernel.\n",
      "            Default: 2.5.\n",
      "\n",
      "        psfsize : int, optional\n",
      "            Size of the kernel to calculate. Returned kernel will have size\n",
      "            psfsize x psfsize. psfsize should be odd. Default: 7.\n",
      "\n",
      "        psfbeta : float, optional\n",
      "            Moffat beta parameter. Only used if fsmode=='convolve' and\n",
      "            psfmodel=='moffat'. Default: 4.765.\n",
      "\n",
      "        verbose : boolean, optional\n",
      "            Print to the screen or not. Default: False.\n",
      "\n",
      "        debug : bool\n",
      "            Enable plots for debugging and store object and sky fits in the\n",
      "            ad objects.\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "flatCorrect\n",
      "\n",
      "        This primitive will divide each SCI extension of the inputs by those\n",
      "        of the corresponding flat. If the inputs contain VAR or DQ frames,\n",
      "        those will also be updated accordingly due to the division on the data.\n",
      "        If no flatfield is provided, the calibration database(s) will be\n",
      "        queried.\n",
      "\n",
      "        If the flatfield has had a QE correction applied, this information is\n",
      "        copied into the science header to avoid the correction being applied\n",
      "        twice.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        flat: str\n",
      "            name of flatfield to use\n",
      "        do_flat: bool\n",
      "            perform flatfield correction?\n",
      "        \n",
      "\n",
      "\n",
      "flushPixels\n",
      "\n",
      "        This primitive saves the inputs to disk and then reopens them so\n",
      "        the pixel data are out of memory\n",
      "        \n",
      "\n",
      "\n",
      "fluxCalibrate\n",
      "\n",
      "        Performs flux calibration multiplying the input signal by the\n",
      "        sensitivity function obtained from\n",
      "        :meth:`~geminidr.core.primitives_spect.Spec.calculateSensitivity`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            1D or 2D Spectra of targets that need to be flux-calibrated.\n",
      "            2D spectra are expected to be distortion corrected and its\n",
      "            dispersion axis should be along rows.\n",
      "\n",
      "        suffix :  str\n",
      "            Suffix to be added to output files (default: _fluxCalibrated).\n",
      "\n",
      "        standard: str or AstroData\n",
      "            Standard star spectrum containing one extension or the same number\n",
      "            of extensions as the input spectra. Each extension must have a\n",
      "            `.SENSFUNC` table containing information about the overall\n",
      "            sensitivity. Right now, if this is not provided, it will raise a\n",
      "            NotImplementedError since it needs implementation.\n",
      "\n",
      "        units : str, optional\n",
      "            Units for output spectrum (default: W m-2 nm-1).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The same input list is used as output but each object now has\n",
      "            its pixel values in physical units.\n",
      "        \n",
      "\n",
      "\n",
      "getBPM\n",
      "None\n",
      "\n",
      "\n",
      "getList\n",
      "\n",
      "        This primitive will check the files in the stack lists are on disk,\n",
      "        and then update the inputs list to include all members that belong\n",
      "        to the same stack(s) as the input(s). All images are cleared from\n",
      "        memory. If the input(s) come from different stacks, images will be\n",
      "        collected from the stacks in the order of the inputs, until the\n",
      "        maximum number of frames is reached.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        purpose: str\n",
      "            purpose/name of list to access\n",
      "        max_frames: int\n",
      "            maximum number of frames to return\n",
      "        \n",
      "\n",
      "\n",
      "getMDF\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedArc\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedBias\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedDark\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedFlat\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedFringe\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedSlitIllum\n",
      "None\n",
      "\n",
      "\n",
      "getProcessedStandard\n",
      "None\n",
      "\n",
      "\n",
      "inspect\n",
      "\n",
      "        Loop through the data, with a pause between the display.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        pause: int\n",
      "            Pause in seconds to add between the display.\n",
      "        \n",
      "\n",
      "\n",
      "linearizeSpectra\n",
      "\n",
      "        Transforms 1D spectra so that the relationship between the pixel\n",
      "        location and wavelength is linear. This primitive calls\n",
      "        resampleToCommonFrame to do the actual resampling.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Wavelength calibrated 1D spectra.\n",
      "\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        w1 : float\n",
      "            Wavelength of first pixel (nm). See Notes below.\n",
      "        w2 : float\n",
      "            Wavelength of last pixel (nm). See Notes below.\n",
      "        dw : float\n",
      "            Dispersion (nm/pixel). See Notes below.\n",
      "        npix : int\n",
      "            Number of pixels in output spectrum. See Notes below.\n",
      "        conserve : bool\n",
      "            Conserve flux (rather than interpolate)?\n",
      "        interpolant : str\n",
      "            type of interpolant\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Exactly 0 or 3 of (w1, w2, dw, npix) must be specified.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Linearized 1D spectra.\n",
      "        \n",
      "\n",
      "\n",
      "makeIRAFCompatible\n",
      "\n",
      "        Add keywords to make the pipeline-processed file compatible\n",
      "        with the tasks in the Gemini IRAF package.\n",
      "        \n",
      "\n",
      "\n",
      "makeSky\n",
      "None\n",
      "\n",
      "\n",
      "makeSlitIllum\n",
      "\n",
      "        Makes the processed Slit Illumination Function by binning a 2D\n",
      "        spectrum along the dispersion direction, fitting a smooth function\n",
      "        for each bin, fitting a smooth 2D model, and reconstructing the 2D\n",
      "        array using this last model.\n",
      "\n",
      "        Its implementation based on the IRAF's `noao.twodspec.longslit.illumination`\n",
      "        task following the algorithm described in [Valdes, 1968].\n",
      "\n",
      "        It expects an input calibration image to be an a dispersed image of the\n",
      "        slit without illumination problems (e.g, twilight flat). The spectra is\n",
      "        not required to be smooth in wavelength and may contain strong emission\n",
      "        and absorption lines. The image should contain a `.mask` attribute in\n",
      "        each extension, and it is expected to be overscan and bias corrected.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list\n",
      "            List of AstroData objects containing the dispersed image of the\n",
      "            slit of a source free of illumination problems. The data needs to\n",
      "            have been overscan and bias corrected and is expected to have a\n",
      "            Data Quality mask.\n",
      "        bins : {None, int}, optional\n",
      "            Total number of bins across the dispersion axis. If None,\n",
      "            the number of bins will match the number of extensions on each\n",
      "            input AstroData object. It it is an int, it will create N bins\n",
      "            with the same size.\n",
      "        border : int, optional\n",
      "            Border size that is added on every edge of the slit illumination\n",
      "            image before cutting it down to the input AstroData frame.\n",
      "        smooth_order : int, optional\n",
      "            Order of the spline that is used in each bin fitting to smooth\n",
      "            the data (Default: 3)\n",
      "        x_order : int, optional\n",
      "            Order of the x-component in the Chebyshev2D model used to\n",
      "            reconstruct the 2D data from the binned data.\n",
      "        y_order : int, optional\n",
      "            Order of the y-component in the Chebyshev2D model used to\n",
      "            reconstruct the 2D data from the binned data.\n",
      "\n",
      "        Return\n",
      "        ------\n",
      "        List of AstroData : containing an AstroData with the Slit Illumination\n",
      "            Response Function for each of the input object.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [Valdes, 1968] Francisco Valdes \"Reduction Of Long Slit Spectra With\n",
      "           IRAF\", Proc. SPIE 0627, Instrumentation in Astronomy VI,\n",
      "           (13 October 1986); https://doi.org/10.1117/12.968155\n",
      "        \n",
      "\n",
      "\n",
      "maskBeyondSlit\n",
      "\n",
      "        This primitive masks unilluminated regions defined by a mask definition\n",
      "        file (MDF).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Spectra with unilluminated regions.\n",
      "        suffix : str\n",
      "            Suffix to append to the filename.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Spectra with regions outside the illuminated region masked.\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "maskFaultyAmp\n",
      "None\n",
      "\n",
      "\n",
      "measureBG\n",
      "\n",
      "        This primitive measures the sky background level for an image by\n",
      "        sampling the non-object unflagged pixels in each extension.\n",
      "\n",
      "        The count levels are then converted to a flux using the nominal\n",
      "        (*not* measured) Zeropoint values - the point being you want to measure\n",
      "        the actual background level, not the flux incident on the top of the\n",
      "        cloud layer necessary to produce that flux level.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str\n",
      "            suffix to be added to output files\n",
      "        remove_bias : bool\n",
      "            remove the bias level (if present) before measuring background?\n",
      "        separate_ext : bool\n",
      "            report one value per extension, instead of a global value?\n",
      "        \n",
      "\n",
      "\n",
      "measureCC\n",
      "\n",
      "        This primitive will determine the zeropoint by looking at sources in\n",
      "        the OBJCAT for which a reference catalog magnitude has been determined\n",
      "\n",
      "        It will also compare the measured zeropoint against the nominal\n",
      "        zeropoint for the instrument and the nominal atmospheric extinction\n",
      "        as a function of airmass, to compute the estimated cloud attenuation.\n",
      "\n",
      "        This function is for use with SExtractor-style source-detection.\n",
      "        It relies on having already added a reference catalog and done the\n",
      "        cross match to populate the refmag column of the objcat\n",
      "\n",
      "        The reference magnitudes (refmag) are straight from the reference\n",
      "        catalog. The measured magnitudes (mags) are straight from the object\n",
      "        detection catalog.\n",
      "\n",
      "        We correct for atmospheric extinction at the point where we\n",
      "        calculate the zeropoint, ie we define::\n",
      "\n",
      "            actual_mag = zeropoint + instrumental_mag + extinction_correction\n",
      "\n",
      "        where in this case, actual_mag is the refmag, instrumental_mag is\n",
      "        the mag from the objcat, and we use the nominal extinction value as\n",
      "        we don't have a measured one at this point. ie  we're actually\n",
      "        computing zeropoint as::\n",
      "\n",
      "            zeropoint = refmag - mag - nominal_extinction_correction\n",
      "\n",
      "        Then we can treat zeropoint as::\n",
      "\n",
      "            zeropoint = nominal_photometric_zeropoint - cloud_extinction\n",
      "\n",
      "        to estimate the cloud extinction.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "measureIQ\n",
      "\n",
      "        This primitive is for use with sextractor-style source-detection.\n",
      "        FWHM (from _profile_sources()) and CLASS_STAR (from SExtractor)\n",
      "        are already in OBJCAT; this function does the clipping and reporting\n",
      "        only. Measured FWHM is converted to zenith using airmass^(-0.6).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str\n",
      "            suffix to be added to output files\n",
      "        remove_bias : bool [only for some instruments]\n",
      "            remove the bias level (if present) before displaying?\n",
      "        separate_ext : bool\n",
      "            report one value per extension, instead of a global value?\n",
      "        display : bool\n",
      "            display the images?\n",
      "        \n",
      "\n",
      "\n",
      "mergeInputs\n",
      "\n",
      "        This primitive takes all the inputs in a stream and makes a single\n",
      "        AstroData object containing all the extensions from all the inputs.\n",
      "        \n",
      "\n",
      "\n",
      "mosaicDetectors\n",
      "\n",
      "        This primitive does a full mosaic of all the arrays in an AD object.\n",
      "        An appropriate geometry_conf.py module containing geometric information\n",
      "        is required.\n",
      "\n",
      "        The read noise keyword of the output extensions are set to the mean\n",
      "        of the read noise values returned by the input extensions being tiled.\n",
      "        The gain keyword of the output is set similarly, with a warning logged\n",
      "        if this is the case.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files.\n",
      "        sci_only: bool\n",
      "            mosaic only SCI image data. Default is False\n",
      "        interpolant: str\n",
      "            type of interpolant\n",
      "        \n",
      "\n",
      "\n",
      "nonlinearityCorrect\n",
      "\n",
      "        Apply a generic non-linearity correction to data.\n",
      "        At present (based on GSAOI implementation) this assumes/requires that\n",
      "        the correction is polynomial. The ad.non_linear_coeffs() descriptor\n",
      "        should return the coefficients in ascending order of power\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "normalizeFlat\n",
      "\n",
      "        This primitive normalizes a GMOS Longslit spectroscopic flatfield\n",
      "        in a manner similar to that performed by gsflat in Gemini-IRAF.\n",
      "        A cubic spline is fitted along the dispersion direction of each\n",
      "        row, separately for each CCD.\n",
      "\n",
      "        As this primitive is GMOS-specific, we know the dispersion direction\n",
      "        will be along the rows, and there will be 3 CCDs.\n",
      "\n",
      "        For Hamamatsu CCDs, the 21 unbinned columns at each CCD edge are\n",
      "        masked out, following the procedure in gsflat.\n",
      "        TODO: Should we add these in the BPM?\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix : str/None\n",
      "            suffix to be added to output files\n",
      "        center : int/None\n",
      "            central row/column for 1D extraction (None => use middle)\n",
      "        nsum : int\n",
      "            number of rows/columns around center to combine\n",
      "        function : str\n",
      "            type of function to fit (splineN or polynomial types)\n",
      "        order : int/str\n",
      "            Order of the spline fit to be performed\n",
      "            (can be 3 ints, separated by commas)\n",
      "        lsigma : float/None\n",
      "            lower rejection limit in standard deviations\n",
      "        hsigma : float/None\n",
      "            upper rejection limit in standard deviations\n",
      "        niter : int\n",
      "            maximum number of rejection iterations\n",
      "        grow : float/False\n",
      "            growth radius for rejected pixels\n",
      "        threshold : float\n",
      "            threshold (relative to peak) for flagging unilluminated pixels\n",
      "        interactive : bool\n",
      "            set to activate an interactive preview to fine tune the input parameters\n",
      "        \n",
      "\n",
      "\n",
      "overscanCorrect\n",
      "None\n",
      "\n",
      "\n",
      "plotSpectraForQA\n",
      "\n",
      "        Converts AstroData containing extracted spectra into a JSON object. Then,\n",
      "        push it to the Automated Dataflow Coordination Center (ADCC) Server\n",
      "        (see notes below) using a POST request.\n",
      "\n",
      "        This will allow the spectra to be visualized using the QAP SpecViewer\n",
      "        web browser client.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This primitive only works if the (ADCC) Server is running locally.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Input data containing extracted spectra.\n",
      "        url : str\n",
      "            URL address to the ADCC server.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Data used for plotting.\n",
      "        \n",
      "\n",
      "\n",
      "prepare\n",
      "\n",
      "        Validate and standardize the datasets to ensure compatibility\n",
      "        with the subsequent primitives.  The outputs, if written to\n",
      "        disk will be given the suffix \"_prepared\".\n",
      "\n",
      "        Currently, there are no input parameters associated with\n",
      "        this primitive.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : None or list\n",
      "            Input files that will be prepared. If `None`, it runs on the\n",
      "            list of AstroData objects in the main stream.\n",
      "        suffix: str\n",
      "            Suffix to be added to output files (Default: \"_prepared\").\n",
      "        \n",
      "\n",
      "\n",
      "rejectInputs\n",
      "\n",
      "        This primitive removes a set number of frames from the start and end of the\n",
      "        input list.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        at_start: int\n",
      "            Number of frames to cull from start of input list\n",
      "        at_end: int\n",
      "            Number of frames to cull from end of input list\n",
      "        \n",
      "\n",
      "\n",
      "removeFromInputs\n",
      "\n",
      "        Removes frames whose tags match any one of a list of supplied tags.\n",
      "        The user is likely to want to redirect the output list.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        tags: str/None\n",
      "            Tags which frames must match to be selected\n",
      "        \n",
      "\n",
      "\n",
      "resampleToCommonFrame\n",
      "\n",
      "        Resample 1D or 2D spectra on a common frame, and optionally transform\n",
      "        them so that the relationship between them and their respective\n",
      "        wavelength calibration is linear.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Wavelength calibrated 1D or 2D spectra.\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "        w1 : float\n",
      "            Wavelength of first pixel (nm). See Notes below.\n",
      "        w2 : float\n",
      "            Wavelength of last pixel (nm). See Notes below.\n",
      "        dw : float\n",
      "            Dispersion (nm/pixel). See Notes below.\n",
      "        npix : int\n",
      "            Number of pixels in output spectrum. See Notes below.\n",
      "        conserve : bool\n",
      "            Conserve flux (rather than interpolate)?\n",
      "        interpolant : str\n",
      "            type of interpolant\n",
      "        trim_spatial : bool\n",
      "            Output data will cover the intersection (rather than union) of\n",
      "            the inputs' spatial coverage?\n",
      "        trim_spectral: bool\n",
      "            Output data will cover the intersection (rather than union) of\n",
      "            the inputs' wavelength coverage?\n",
      "        force_linear : bool\n",
      "            Force a linear output wavelength solution?\n",
      "        dq_threshold : float\n",
      "            The fraction of a pixel's contribution from a DQ-flagged pixel to\n",
      "            be considered 'bad' and also flagged.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        If ``w1`` or ``w2`` are not specified, they are computed from the\n",
      "        individual spectra: if ``trim_data`` is True, this is the intersection\n",
      "        of the spectra ranges, otherwise this is the union of all ranges,\n",
      "\n",
      "        If ``dw`` or ``npix`` are specified, the spectra are linearized.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Linearized 1D spectra.\n",
      "        \n",
      "\n",
      "\n",
      "scaleByExposureTime\n",
      "\n",
      "        This primitive scales input images to have the same effective exposure\n",
      "        time. This can either be provided as a parameter, or the images will be\n",
      "        scaled to match the exposure time of the first image in the input list.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str/None\n",
      "            suffix to be added to output files\n",
      "        time: float/None\n",
      "            exposure time to scale to (None => use first image's exposure time)\n",
      "        \n",
      "\n",
      "\n",
      "scaleCountsToReference\n",
      "\n",
      "        This primitive scales the input images so that the scaled fluxes of\n",
      "        the sources in the OBJCAT match those in the reference image (the\n",
      "        first image in the list). By setting the input parameter tolerance=0,\n",
      "        it is possible to simply scale the images by the exposure times.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        tolerance: float (0 <= tolerance <= 1)\n",
      "            tolerance within which scaling must match exposure time to be used\n",
      "        use_common: bool\n",
      "            use only sources common to all frames?\n",
      "        radius: float\n",
      "            matching radius in arcseconds\n",
      "        \n",
      "\n",
      "\n",
      "selectFromInputs\n",
      "\n",
      "        Selects frames whose tags match any one of a list of supplied tags.\n",
      "        The user is likely to want to redirect the output list.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        tags: str/None\n",
      "            Tags which frames must match to be selected\n",
      "        \n",
      "\n",
      "\n",
      "separateSky\n",
      "\n",
      "        Given a set of input exposures, sort them into separate but\n",
      "        possibly-overlapping streams of on-target and sky frames. This is\n",
      "        achieved by dividing the data into distinct pointing/dither groups,\n",
      "        applying a set of rules to classify each group as target(s) or sky\n",
      "        and optionally overriding those classifications with user guidance\n",
      "        (up to and including full manual specification of both lists).\n",
      "\n",
      "        If all exposures are found to be on source then both output streams\n",
      "        will replicate the input. Where a dataset appears in both lists, a\n",
      "        separate copy (TBC: copy-on-write?) is made in the sky list to avoid\n",
      "        subsequent operations on one of the output lists affecting the other.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        frac_FOV: float\n",
      "            Proportion by which to scale the instrumental field of view when\n",
      "            determining whether points are considered to be within the same\n",
      "            field, for tweaking borderline cases (eg. to avoid co-adding\n",
      "            target positions right at the edge of the field)\n",
      "        ref_obj: str\n",
      "            comma-separated list of filenames (as read from disk, without any\n",
      "            additional suffixes appended) to be considered object/on-target\n",
      "            exposures, as overriding guidance for any automatic classification.\n",
      "        ref_sky: str\n",
      "            comma-separated list of filenames to be considered as sky exposures\n",
      "\n",
      "        Any existing OBJFRAME or SKYFRAME flags in the input meta-data will\n",
      "        also be respected as input (unless overridden by ref_obj/ref_sky) and\n",
      "        these same keywords are set in the output, along with a group number\n",
      "        with which each exposure is associated (EXPGROUP).\n",
      "        \n",
      "\n",
      "\n",
      "setCalibration\n",
      "\n",
      "        Manually assigns a calibration to one or more frames. This is expected\n",
      "        to only affect the UserDB, since other databases do not have a way to\n",
      "        override the calibration association rules in isolation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : <list>\n",
      "            List of ADs of files for which calibrations are needed\n",
      "\n",
      "        caltype : <str>\n",
      "            type of calibration required (e.g., \"processed_bias\")\n",
      "\n",
      "        calfile : <str>\n",
      "            filename of calibration\n",
      "        \n",
      "\n",
      "\n",
      "shiftImages\n",
      "\n",
      "        This primitive will shift images by user-defined amounts along each\n",
      "        axis.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        shifts: str\n",
      "            either: (a) list of colon-separated xshift,yshift pairs, or\n",
      "                    (b) filename containing shifts, one set per image\n",
      "        interpolant : str\n",
      "            type of interpolant\n",
      "        trim_data: bool\n",
      "            trim image to size of reference image?\n",
      "        clean_data: bool\n",
      "            replace bad pixels with a ring median of their values to avoid\n",
      "            ringing if using a high-order interpolation?\n",
      "        dq_threshold : float\n",
      "            The fraction of a pixel's contribution from a DQ-flagged pixel to\n",
      "            be considered 'bad' and also flagged.\n",
      "        \n",
      "\n",
      "\n",
      "showInputs\n",
      "\n",
      "        A simple primitive to show the filenames for the current inputs to\n",
      "        this primitive.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        purpose: str\n",
      "            Brief description for output\n",
      "        \n",
      "\n",
      "\n",
      "showList\n",
      "\n",
      "        This primitive will log the list of files in the stacking list matching\n",
      "        the current inputs and 'purpose' value.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        purpose: str\n",
      "            purpose/name of list\n",
      "        \n",
      "\n",
      "\n",
      "skyCorrect\n",
      "\n",
      "        This primitive subtracts a sky frame from each of the science inputs.\n",
      "        Each science input should have a list of skies in a SKYTABLE extension\n",
      "        and these are stacked and subtracted, using the appropriate primitives.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        apply_dq: bool\n",
      "            apply DQ mask to data before combining?\n",
      "        statsec: str/None\n",
      "            region of image to use for statistics\n",
      "        operation: str\n",
      "            type of combining operation for stacking sky frames\n",
      "        reject_method: str\n",
      "            type of rejection method for stacking sky frames\n",
      "        mask_objects: bool\n",
      "            mask objects using OBJMASK?\n",
      "        dilation: float\n",
      "            dilation radius if objects are being masked\n",
      "        hsigma: float\n",
      "            high rejection threshold (standard deviations)\n",
      "        lsigma: float\n",
      "            low rejection threshold (standard deviations)\n",
      "        mclip: bool\n",
      "            use median (rather than mean) for sigma-clipping?\n",
      "        nlow: int\n",
      "            number of low pixels to reject (for \"minmax\")\n",
      "        nhigh: int\n",
      "            number of high pixels to reject (for \"minmax\")\n",
      "        memory: float/None\n",
      "            available memory (in GB) for stacking calculations\n",
      "        reset_sky: bool\n",
      "            maintain the sky level by adding a constant to the science\n",
      "            frame after subtracting the sky?\n",
      "        scale_sky: bool\n",
      "            scale each extension of each sky frame to match the science frame?\n",
      "        offset_sky: bool\n",
      "            apply offset to each extension of each sky frame to match science?\n",
      "        sky: str/AD/list\n",
      "            sky frame(s) to subtract\n",
      "        \n",
      "\n",
      "\n",
      "skyCorrectFromSlit\n",
      "\n",
      "        Performs row-by-row/column-by-column sky subtraction of 2D spectra.\n",
      "\n",
      "        For that, it fits the sky contribution along each row/column\n",
      "        perpendicular to the dispersion axis and builds a mask of rejected\n",
      "        pixels during the fitting process. It also adds any apertures defined\n",
      "        in the APERTURE table to this mask if it exists.\n",
      "\n",
      "        This primitive should be called on data free of distortion.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            2D science spectra loaded as :class:`~astrodata.AstroData` objects.\n",
      "        suffix : str or None\n",
      "            Suffix to be added to output files.\n",
      "        regions : str or None\n",
      "            Sample region(s) to fit along rows/columns parallel to the slit,\n",
      "            as a comma-separated list of pixel ranges. Any pixels outside these\n",
      "            ranges (and/or included in the source aperture table) will be\n",
      "            ignored when fitting each row or column.\n",
      "        function : {'splineN', 'legendre', 'chebyshev', 'polynomial'}, optional\n",
      "            Type of function/model to be used for fitting rows or columns\n",
      "            perpendicular to the dispersion axis (default 'spline3', a cubic\n",
      "            spline). For spline fits, N may be 1-5 (linear to quintic).\n",
      "        order : int or None\n",
      "            Order of fit to each row/column. For spline fits, this\n",
      "            is the number of spline pieces; if `None`, as many pieces will be\n",
      "            used as are required to get chi^2=1, otherwise the specified number\n",
      "            will be reduced in proportion to the ratio of good pixels to total\n",
      "            pixels in each row/column. If there are fewer than 4 good pixels in\n",
      "            a given row/column, the fit will be performed using every pixel.\n",
      "            For polynomial fitting functions, ``order`` is the polynomial degree\n",
      "        lsigma, hsigma : float\n",
      "            Lower and upper pixel rejection limits for fitting, in standard\n",
      "            deviations from the fit\n",
      "        niter : int\n",
      "            Maximum number of fitting iterations\n",
      "        grow : float or False, optional\n",
      "            Masking growth radius (in pixels) for each statistically-rejected pixel\n",
      "        aperture_growth : float\n",
      "            Masking growth radius (in pixels) for each aperture\n",
      "        debug_plot : bool\n",
      "            Show diagnostic plots?\n",
      "        interactive : bool\n",
      "            Show interactive interface?\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Sky subtractd 2D spectral images.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        :meth:`~geminidr.core.primitives_spect.Spect.determineDistortion`,\n",
      "        :meth:`~geminidr.core.primitives_spect.Spect.distortionCorrect`,\n",
      "        :meth:`~geminidr.core.primitives_spect.Spect.findApertures`,\n",
      "        \n",
      "\n",
      "\n",
      "sliceIntoStreams\n",
      "\n",
      "        This primitive slices each input AstroData object into separate AD\n",
      "        objects with one slice each, and puts them into separate streams. The\n",
      "        stream \"index0\" will contain all the first slices from all the AD\n",
      "        objects, \"index1\" all the second slices, and so on. These streams will\n",
      "        not be the same length if the input AD objects have different lengths.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        root_stream_name: str\n",
      "            base name for the streams (to be succeeded by 1, 2, 3, ...)\n",
      "        copy: bool\n",
      "            make full deepcopies of the slices?\n",
      "        \n",
      "\n",
      "\n",
      "slitIllumCorrect\n",
      "\n",
      "        This primitive will divide each SCI extension of the inputs by those\n",
      "        of the corresponding slit illumination image. If the inputs contain\n",
      "        VAR or DQ frames, those will also be updated accordingly due to the\n",
      "        division on the data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of AstroData\n",
      "            Data to be corrected.\n",
      "        slit_illum : str or AstroData\n",
      "            Slit illumination path or AstroData object.\n",
      "        do_cal: str\n",
      "            Perform slit illumination correction? (Default: 'procmode')\n",
      "        \n",
      "\n",
      "\n",
      "sortInputs\n",
      "\n",
      "        This sorts the input list according to the values returned by the\n",
      "        descriptor parameter.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        descriptor: str\n",
      "            name of descriptor on which to sort (can also be \"filename\")\n",
      "        reverse: bool\n",
      "            return list sorted in reverse order?\n",
      "        \n",
      "\n",
      "\n",
      "stackBiases\n",
      "\n",
      "        This primitive stacks the inputs without any scaling or offsetting,\n",
      "        suitable for biases.\n",
      "        \n",
      "\n",
      "\n",
      "stackDarks\n",
      "\n",
      "        This primitive checks the inputs have the same exposure time and\n",
      "        stacks them without any scaling or offsetting, suitable for darks.\n",
      "        \n",
      "\n",
      "\n",
      "stackFlats\n",
      "This primitive stacks the inputs without offsetting, suitable\n",
      "        for flats.\n",
      "\n",
      "\n",
      "stackFrames\n",
      "\n",
      "        This primitive will stack each science extension in the input dataset.\n",
      "        New variance extensions are created from the stacked science extensions\n",
      "        and the data quality extensions are propagated through to the final\n",
      "        file.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Any set of 2D.\n",
      "\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "\n",
      "        apply_dq : bool\n",
      "            Apply DQ mask to data before combining?\n",
      "\n",
      "        nlow, nhigh : int\n",
      "            Number of low and high pixels to reject, for the 'minmax' method.\n",
      "            The way it works is inherited from IRAF: the fraction is specified\n",
      "            as the number of  high  and low  pixels,  the  nhigh and nlow\n",
      "            parameters, when data from all the input images are used.  If\n",
      "            pixels  have  been  rejected  by offseting,  masking, or\n",
      "            thresholding then a matching fraction of the remaining pixels,\n",
      "            truncated to an integer, are used.  Thus::\n",
      "\n",
      "                nl = n * nlow/nimages + 0.001\n",
      "                nh = n * nhigh/nimages + 0.001\n",
      "\n",
      "            where n is the number of pixels  surviving  offseting,  masking,\n",
      "            and  thresholding,  nimages  is the number of input images, nlow\n",
      "            and nhigh are task parameters  and  nl  and  nh  are  the  final\n",
      "            number  of  low  and high pixels rejected by the algorithm.  The\n",
      "            factor of 0.001 is to adjust for rounding of the ratio.\n",
      "\n",
      "        operation : str\n",
      "            Combine method.\n",
      "\n",
      "        reject_method : str\n",
      "            Pixel rejection method (none, minmax, sigclip, varclip).\n",
      "\n",
      "        zero : bool\n",
      "            Apply zero-level offset to match background levels?\n",
      "\n",
      "        scale : bool\n",
      "            Scale images to the same intensity?\n",
      "\n",
      "        memory : float or None\n",
      "            Available memory (in GB) for stacking calculations.\n",
      "\n",
      "        statsec : str\n",
      "            Section for statistics.\n",
      "\n",
      "        separate_ext : bool\n",
      "            Handle extensions separately?\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Sky stacked image. This list contains only one element. The list\n",
      "            format is maintained so this primitive is consistent with all the\n",
      "            others.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        IOError\n",
      "            If the number of extensions in any of the `AstroData` objects is\n",
      "            different.\n",
      "\n",
      "        IOError\n",
      "            If the shape of any extension in any `AstroData` object is different.\n",
      "\n",
      "        AssertError\n",
      "            If any of the `.gain()` descriptors is None.\n",
      "\n",
      "        AssertError\n",
      "            If any of the `.read_noise()` descriptors is None.\n",
      "        \n",
      "\n",
      "\n",
      "stackSkyFrames\n",
      "\n",
      "        Adds the `OBJMASK` object mask to the `DQ` data quality plane for every\n",
      "        image and its extensions. Then, stacks all the images into a single\n",
      "        frame.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Science images with objects properly detected and added to the\n",
      "            `OBJMASK` plane.\n",
      "\n",
      "        suffix : str\n",
      "            Suffix to be added to output files.\n",
      "\n",
      "        apply_dq : bool\n",
      "            Apply DQ mask to data before combining?\n",
      "\n",
      "        dilation : int\n",
      "            Dilation radius for expanding object mask.\n",
      "\n",
      "        mask_objects : bool\n",
      "            Mask objects from the input frames?\n",
      "\n",
      "        nhigh : int\n",
      "            Number of high pixels to reject.\n",
      "\n",
      "        nlow : int\n",
      "            Number of low pixels to reject.\n",
      "\n",
      "        operation : str\n",
      "            Combine method.\n",
      "\n",
      "        reject_method : str\n",
      "            Type of pixel rejection (passed to gemcombine).\n",
      "\n",
      "        memory : float or None\n",
      "            Available memory (in GB) for stacking calculations.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Sky stacked image. This list contains only one element. The list\n",
      "            format is maintained so this primitive is consistent with all the\n",
      "            others.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        :meth:`~geminidr.core.primitives_stack.Stack.stackFrames`\n",
      "        \n",
      "\n",
      "\n",
      "standardizeHeaders\n",
      "\n",
      "        This primitive is used to standardize the headers of data. It adds\n",
      "        the ORIGNAME keyword and then calls the standardizeObservatoryHeaders\n",
      "        and standardizeInstrumentHeaders primitives.\n",
      "        \n",
      "\n",
      "\n",
      "standardizeInstrumentHeaders\n",
      "\n",
      "        This primitive is used to make the changes and additions to the\n",
      "        keywords in the headers of GMOS data, specifically.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "standardizeObservatoryHeaders\n",
      "\n",
      "        This primitive is used to make the changes and additions to the\n",
      "        keywords in the headers of Gemini data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "standardizeStructure\n",
      "\n",
      "        This primitive is used to standardize the structure of Gemini data,\n",
      "        specifically.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        attach_mdf: bool\n",
      "            attach an MDF to the AD objects?\n",
      "        mdf: str\n",
      "            full path of the MDF to attach\n",
      "        \n",
      "\n",
      "\n",
      "standardizeWCS\n",
      "\n",
      "        This primitive updates the WCS attribute of each NDAstroData extension\n",
      "        in the input AstroData objects. For spectroscopic data, it means\n",
      "        replacing an imaging WCS with an approximate spectroscopic WCS.\n",
      "\n",
      "        This is a GMOS-specific primitive due to the systematic offsets for\n",
      "        GMOS-S at central wavelengths > 950nm.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str/None\n",
      "            suffix to be added to output files\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "storeBPM\n",
      "None\n",
      "\n",
      "\n",
      "storeCalibration\n",
      "\n",
      "        Farm some calibration ADs out to the calibration database(s) to process.\n",
      "        \n",
      "\n",
      "\n",
      "storeProcessedArc\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedBias\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedDark\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedFlat\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedFringe\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedScience\n",
      "None\n",
      "\n",
      "\n",
      "storeProcessedSlitIllum\n",
      "\n",
      "        Stores the Processed Slit Illumination file.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of AstroData\n",
      "            Data that contain the Slit Illumination Response Function.\n",
      "        suffix : str\n",
      "            Suffix to be added to each of the input files.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of AstroData : the input data is simply forwarded.\n",
      "        \n",
      "\n",
      "\n",
      "storeProcessedStandard\n",
      "None\n",
      "\n",
      "\n",
      "subtractOverscan\n",
      "\n",
      "        This primitive subtracts the overscan level from the image. The\n",
      "        level for each row (currently the primitive requires that the overscan\n",
      "        region be a vertical strip) is determined in one of the following\n",
      "        ways, according to the *function* and *order* parameters:\n",
      "\n",
      "        :\"poly\":   a polynomial of degree *order* (1=linear, etc)\n",
      "        :\"spline\": using *order* equally-sized cubic spline pieces or, if\n",
      "                  order=None or 0, a spline that provides a reduced chi^2=1\n",
      "        :\"none\":   no function is fit, and the value for each row is determined\n",
      "                  by the overscan pixels in that row\n",
      "\n",
      "        The fitting is done iteratively but, in the first instance, a running\n",
      "        median of the rows is calculated and rows that deviate from this median\n",
      "        are rejected (and used in place of the actual value if function=\"none\")\n",
      "\n",
      "        The GMOS-specific version of this primitive sets the \"nbiascontam\" and\n",
      "        \"order\" parameters to their Gemini-IRAF defaults if they are None. It\n",
      "        also removes the bottom 48 (ubinned) rows of the Hamamatsu CCDs from\n",
      "        consideration in a polynomial fit. It then calls the generic version\n",
      "        of the primitive.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        niterate: int\n",
      "            number of rejection iterations\n",
      "        high_reject: float\n",
      "            number of standard deviations above which to reject high pixels\n",
      "        low_reject: float\n",
      "            number of standard deviations above which to reject low pixels\n",
      "        overscan_section: str/None\n",
      "            comma-separated list of IRAF-style overscan sections\n",
      "        nbiascontam: int/None\n",
      "            number of columns adjacent to the illuminated region to reject\n",
      "        function: str\n",
      "            function to fit (\"polynomial\" | \"spline\" | \"none\")\n",
      "        order: int\n",
      "            order of Chebyshev fit or spline/None\n",
      "        \n",
      "\n",
      "\n",
      "subtractSky\n",
      "\n",
      "        This function will subtract the science extension of the input sky\n",
      "        (or other) frames from the science extension of the input science\n",
      "        frames. The variance and data quality extension will be updated, if\n",
      "        they exist.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        reset_sky: bool\n",
      "            maintain the sky level by adding a constant to the science\n",
      "            frame after subtracting the sky?\n",
      "        scale_sky: bool\n",
      "            scale each extension of each sky frame to match the science frame?\n",
      "        offset_sky: bool\n",
      "            apply offset to each extension of each sky frame to match science?\n",
      "        sky: str/AD/list\n",
      "            sky frame(s) to subtract\n",
      "        \n",
      "\n",
      "\n",
      "subtractSkyBackground\n",
      "\n",
      "        This primitive is used to subtract the sky background specified by\n",
      "        the keyword SKYLEVEL.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "thresholdFlatfield\n",
      "\n",
      "        This primitive sets the DQ '64' bit (unilluminated) for any pixels\n",
      "        which have a value <lower or >upper in the SCI plane.\n",
      "        it also sets the science plane pixel value to 1.0 for pixels which are bad\n",
      "        and very close to zero, to avoid divide by zero issues and inf values\n",
      "        in the flat-fielded science data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        lower: float\n",
      "            value below which DQ pixels should be set to unilluminated\n",
      "        upper: float\n",
      "            value above which DQ pixels should be set to unilluminated\n",
      "        \n",
      "\n",
      "\n",
      "tileArrays\n",
      "\n",
      "        This primitive combines extensions by tiling (no interpolation).\n",
      "        The array_section() and detector_section() descriptors are used\n",
      "        to derive the geometry of the tiling, so outside help (from the\n",
      "        instrument's geometry_conf module) is only required if there are\n",
      "        multiple arrays being tiled together, as the gaps need to be\n",
      "        specified.\n",
      "\n",
      "        If the input AstroData objects still have non-data regions, these\n",
      "        will not be trimmed. However, the WCS of the final image will\n",
      "        only be correct for some of the image since extra space has been\n",
      "        introduced into the image.\n",
      "\n",
      "        The read noise keyword of the output extensions are set to the mean\n",
      "        of the read noise values returned by the input extensions being tiled.\n",
      "        The gain keyword of the output is set similarly, with a warning logged\n",
      "        if this is the case.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        tile_all: bool\n",
      "            tile to a single extension, rather than one per array?\n",
      "            (array=physical detector)\n",
      "        sci_only: bool\n",
      "            tile only the data plane?\n",
      "        \n",
      "\n",
      "\n",
      "traceApertures\n",
      "\n",
      "        Traces apertures listed in the `.APERTURE` table along the dispersion\n",
      "        direction, and estimates the optimal extraction aperture size from the\n",
      "        spatial profile of each source.\n",
      "\n",
      "        This primitive is now designed to run on tiled and mosaicked data so\n",
      "        normal long-slit spectra will be in a single extension. We keep the loop\n",
      "        over extensions to allow the possibility of expanding it to cases where\n",
      "        we have multiple extensions (e.g. Multi-Object Spectroscopy).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images with a `.APERTURE` table attached\n",
      "            to one or more of its extensions.\n",
      "        debug: bool, optional\n",
      "            draw aperture traces on image display window? Default: False\n",
      "        interactive: bool, optional\n",
      "            Run primitive interactively? Default: False\n",
      "        max_missed : int, optional\n",
      "            Maximum number of interactions without finding line before line is\n",
      "            considered lost forever. Default: 5\n",
      "        max_shift : float, optional\n",
      "            Maximum perpendicular shift (in pixels) from pixel to pixel.\n",
      "            Default: 0.05\n",
      "        nsum : int, optional\n",
      "            Number of rows/columns to combine at each step. Default: 10\n",
      "        order : int, optional\n",
      "            Fitting order along spectrum. Default: 2\n",
      "        step : int, optional\n",
      "            Step size for sampling along dispersion direction. Default: 10\n",
      "        suffix : str, optional\n",
      "            Suffix to be added to output files. Default: \"_aperturesTraced\".\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images with the `.APERTURE` the updated\n",
      "            to contain its upper and lower limits.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        :meth:`~geminidr.core.primitives_spect.Spect.findApertures`\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "transferAttribute\n",
      "\n",
      "        This primitive takes an attribute (e.g., \"mask\", or \"OBJCAT\") from\n",
      "        the AD(s) in another (\"source\") stream and applies it to the ADs in\n",
      "        this stream. There must be either the same number of ADs in each\n",
      "        stream, or only 1 in the source stream.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        source: str\n",
      "            name of stream containing ADs whose attributes you want\n",
      "        attribute: str\n",
      "            attribute to transfer from ADs in other stream\n",
      "        \n",
      "\n",
      "\n",
      "transferDistortionModel\n",
      "\n",
      "        This primitive transfers distortion_model from the AD(s) in another (\"source\")\n",
      "        stream to the ADs in this stream if there was none, to match the WCS structure\n",
      "        of processedArc. If the number of ADs in the source stream is larger than\n",
      "        in the current stream, it's assumed that there was frame stacking done in the recipe,\n",
      "        and the distortion_model gets transferred only if the AD's ORIGNAME keywords are matching.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        source: str\n",
      "            name of stream containing ADs whose \"distortion_model\" you want\n",
      "        \n",
      "\n",
      "\n",
      "trimOverscan\n",
      "\n",
      "        The trimOverscan primitive trims the overscan region from the input\n",
      "        AstroData object and updates the headers.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        \n",
      "\n",
      "\n",
      "validateData\n",
      "\n",
      "        This is the data validation primitive. It checks that the instrument\n",
      "        matches the primitivesClass and that there are the correct number\n",
      "        of extensions.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        suffix: str\n",
      "            suffix to be added to output files\n",
      "        require_wcs: bool\n",
      "            do all extensions have to have a defined WCS?\n",
      "        \n",
      "\n",
      "\n",
      "write1DSpectra\n",
      "\n",
      "        Write 1D spectra to files listing the wavelength and data (and\n",
      "        optionally variance and mask) in one of a range of possible formats.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        adinputs : list of :class:`~astrodata.AstroData`\n",
      "            Science data as 2D spectral images.\n",
      "        format : str\n",
      "            format for writing output files\n",
      "        header : bool\n",
      "            write FITS header before data values?\n",
      "        extension : str\n",
      "            extension to be used in output filenames\n",
      "        apertures : str\n",
      "            comma-separated list of aperture numbers to write\n",
      "        dq : bool\n",
      "            write DQ (mask) plane?\n",
      "        var : bool\n",
      "            write VAR (variance) plane?\n",
      "        overwrite : bool\n",
      "            overwrite existing files?\n",
      "        xunits: str\n",
      "            units of the x (wavelength/frequency) column\n",
      "        yunits: str\n",
      "            units of the data column\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        list of :class:`~astrodata.AstroData`\n",
      "            The unmodified input files.\n",
      "        \n",
      "\n",
      "\n",
      "writeOutputs\n",
      "\n",
      "        A primitive that may be called by a recipe at any stage to\n",
      "        write the outputs to disk.\n",
      "        If suffix is set during the call to writeOutputs, any previous\n",
      "        suffixes will be striped and replaced by the one provided.\n",
      "        examples:\n",
      "        writeOutputs(suffix= '_string'), writeOutputs(prefix= '_string')\n",
      "        or if you have a full file name in mind for a SINGLE file being\n",
      "        ran through Reduce you may use writeOutputs(outfilename='name.fits').\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        strip: bool\n",
      "            strip the previous suffix off file name?\n",
      "        overwrite: bool\n",
      "            overwrite existing files?\n",
      "        suffix: str\n",
      "            new suffix to append to output files\n",
      "        prefix: str\n",
      "            new prefix to prepend to output files\n",
      "        outfilename: str\n",
      "            new filename (applicable only if there's one file to be written)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "## let's see all the prmitives/methods in this primitive set\n",
    "\n",
    "for item in dir(p):\n",
    "   if not item.startswith('_') and inspect.ismethod(getattr(p, item)):\n",
    "       print(\"\\n\")\n",
    "       print (item)\n",
    "       print(getattr(p, item).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be238117-4bff-4dbb-99b1-4ffa9c8d7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tagged as {'RAW', 'SPECT', 'SIDEREAL', 'FLAT', 'CAL', 'GEMINI', 'LS', 'GCALFLAT', 'UNPREPARED', 'SOUTH', 'GMOS'}\n",
      "\n",
      "Settable parameters on 'addDQ':\n",
      "========================================\n",
      "Name                 Current setting      Description\n",
      "\n",
      "suffix               '_dqAdded'           Filename suffix\n",
      "illum_mask           None                 Name of illumination mask\n",
      "shift                None                 User-defined shift for illumination mask\n",
      "\tValid Range = [-100,100]\n",
      "max_shift            50                   Maximum (unbinned) pixel shift for illumination mask\n",
      "\tValid Range = [0,100]\n",
      "static_bpm           'default'            Static bad pixel mask\n",
      "user_bpm             None                 User bad pixel mask\n",
      "add_illum_mask       True                 Apply illumination mask?\n",
      "\n",
      "Docstring for 'addDQ':\n",
      "========================================\n",
      "\n",
      "This primitive is used to add a DQ extension to the input AstroData\n",
      "object. The value of a pixel in the DQ extension will be the sum of the\n",
      "following: (0=good, 1=bad pixel (found in bad pixel mask), 2=pixel is\n",
      "in the non-linear regime, 4=pixel is saturated). This primitive will\n",
      "trim the BPM to match the input AstroData object(s).\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "suffix: str\n",
      "    suffix to be added to output files\n",
      "static_bpm: str\n",
      "    Name of bad pixel mask (\"default\" -> use default from look-up table)\n",
      "    If set to None, no static_bpm will be added.\n",
      "user_bpm: str\n",
      "    Name of the bad pixel mask created by the user from flats and\n",
      "    darks.  It is an optional BPM that can be added to the static one.\n",
      "add_illum_mask: bool\n",
      "    add illumination mask?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to view parameters assigned for a chosen primitive\n",
    "\n",
    "showpars.showpars(p, 'addDQ', tags, show_docstring=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89417518-8e0f-408b-af42-880805cd22dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def makeProcessedFlatNoStack(p):\n",
      "    p.prepare()\n",
      "    p.addDQ()\n",
      "    p.addVAR(read_noise=True)\n",
      "    p.overscanCorrect()\n",
      "    p.biasCorrect()\n",
      "    p.ADUToElectrons()\n",
      "    p.addVAR(poisson_noise=True)\n",
      "    p.normalizeFlat()\n",
      "    p.thresholdFlatfield()\n",
      "    p.makeIRAFCompatible()\n",
      "    p.storeProcessedFlat()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Let's examine the sequence of primitives in the chosen recipe \n",
    "print(inspect.getsource(recipe.__code__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc150d0-cab4-4d4f-8a82-ca465e645024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recipe(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "909ae2e3-1a3d-4a27-9b8e-1020503a660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileData(name='S20210211S0068_bias.fits', path='/data/goats_dev_data/example_data/data/ZTF18acppavh/GEM/GS-2021A-DD-102-9/reduction/calibrations/processed_bias')\n",
      "FileData(name='S20210219S0077_flat.fits', path='/data/goats_dev_data/example_data/data/ZTF18acppavh/GEM/GS-2021A-DD-102-9/reduction/calibrations/processed_flat')\n",
      "FileData(name='S20210219S0078_flat.fits', path='/data/goats_dev_data/example_data/data/ZTF18acppavh/GEM/GS-2021A-DD-102-9/reduction/calibrations/processed_flat')\n",
      "FileData(name='bpm_20140601_gmos-s_Ham_22_full_12amp.fits', path='/data/goats_dev_data/example_data/data/ZTF18acppavh/GEM/GS-2021A-DD-102-9')\n"
     ]
    }
   ],
   "source": [
    "for F in caldb.list_files():\n",
    "    print (F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288bb290-1288-4ffb-a4b7-6fcfabb11412",
   "metadata": {},
   "source": [
    "**Let's say the user has customized the flat recipe on GOATS as follows -- adding the interactive=True for nomalizeFlat primitive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1754fc8d-b1f1-4e1c-9f31-b9de6e93fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrecipe(p):\n",
    "    p.prepare()\n",
    "    p.addDQ()\n",
    "    p.addVAR(read_noise=True)\n",
    "    p.overscanCorrect()\n",
    "    p.biasCorrect()\n",
    "    p.ADUToElectrons()\n",
    "    p.addVAR(poisson_noise=True)\n",
    "    p.normalizeFlat(interactive=True) ## user added this customization\n",
    "    p.thresholdFlatfield()\n",
    "    p.makeIRAFCompatible()\n",
    "    p.storeProcessedFlat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee2834-b751-4659-abe8-81f7f8e455a9",
   "metadata": {},
   "source": [
    "**Below shows how we can update the recipe with the customized one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ed4e740-faef-4b51-a144-604c3ce83ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def myrecipe(p):\n",
      "    p.prepare()\n",
      "    p.addDQ()\n",
      "    p.addVAR(read_noise=True)\n",
      "    p.overscanCorrect()\n",
      "    p.biasCorrect()\n",
      "    p.ADUToElectrons()\n",
      "    p.addVAR(poisson_noise=True)\n",
      "    p.normalizeFlat(interactive=True) ## user added this customization\n",
      "    p.thresholdFlatfield()\n",
      "    p.makeIRAFCompatible()\n",
      "    p.storeProcessedFlat()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmapper = RecipeMapper(tags, instpkg, recipename=myrecipe)\n",
    "\n",
    "customized_recipe = rmapper.get_applicable_recipe()\n",
    "\n",
    "print(inspect.getsource(customized_recipe.__code__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ecbc9-f3f6-4bb0-b162-4f2465505d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Run the customized recipe with the pclass instance\n",
    "p = pclass([astrodata.open(F) for F in DF_flat['file'].values], config_file=dragons_rc)\n",
    "\n",
    "customized_recipe(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18295f-1ae2-41d7-977f-1903c8375b9b",
   "metadata": {},
   "source": [
    "# \n",
    "<a id='blah'></a>\n",
    "# Everything handled by `Reduce` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebfc73-2d55-4b84-8ec3-15f73921d8d1",
   "metadata": {},
   "source": [
    "**Here running the default flat recipe. Notice that `interactive=False` by default**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48dd9d8-2a12-474a-89f3-f60fbfdd1b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce = Reduce()\n",
    "reduce.files.extend(DF_flat['file'].values)\n",
    "reduce.config_file = dragons_rc\n",
    "print (f\"Using recipe {reduce.recipename}\")\n",
    "reduce.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe1d04-0a53-4a75-8573-e78ae6f77bf4",
   "metadata": {},
   "source": [
    "**Here let's run the customized recipe `myrecipe` defined below where I set `interactive=True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f15176b3-d08d-4b16-be56-3600ede850ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myrecipe(p):\n",
    "    p.prepare()\n",
    "    p.addDQ()\n",
    "    p.addVAR(read_noise=True)\n",
    "    p.overscanCorrect()\n",
    "    p.biasCorrect()\n",
    "    p.ADUToElectrons()\n",
    "    p.addVAR(poisson_noise=True)\n",
    "    p.normalizeFlat(interactive=True) ## user added this customization\n",
    "    p.thresholdFlatfield()\n",
    "    p.makeIRAFCompatible()\n",
    "    p.storeProcessedFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a342e-3dea-4ca7-8989-693c017fbb25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce = Reduce()\n",
    "reduce.files.extend(DF_flat['file'].values)\n",
    "reduce.config_file = dragons_rc\n",
    "reduce.recipename = myrecipe\n",
    "print (f\"Using recipe {reduce.recipename}\")\n",
    "reduce.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c4b06-2361-4ccc-a1ea-64ecb3a3580c",
   "metadata": {},
   "source": [
    "**Let's customize even further by inserting a primitive to save intermediate products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f55c91-b53b-42d6-aacd-4c9bb4e8b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fabulous_recipe(p):\n",
    "    p.prepare()\n",
    "    p.addDQ()\n",
    "    p.addVAR(read_noise=True)\n",
    "    p.overscanCorrect()\n",
    "    p.biasCorrect()\n",
    "    p.ADUToElectrons()\n",
    "    p.writeOutputs() ## user added this customization\n",
    "    p.addVAR(poisson_noise=True)\n",
    "    p.normalizeFlat(interactive=True) ## user added this customization\n",
    "    p.thresholdFlatfield()\n",
    "    p.makeIRAFCompatible()\n",
    "    p.storeProcessedFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d4a8cc6-de5e-4cda-8f4f-5ca8456fd47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrations\t\t S20210219S0077_flat.fits\n",
      "dragons_for_goats.db\t S20210219S0077_overscanCorrected_crash.fits\n",
      "dragonsrc\t\t S20210219S0078_flat.fits\n",
      "gmos_data_reduction.log  S20210219S0078_overscanCorrected_crash.fits\n"
     ]
    }
   ],
   "source": [
    "## Check the files in the current directory to later verify existence of intermediate data products\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6072ec3-0543-4038-bf5f-f99d561ef653",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = Reduce()\n",
    "reduce.files.extend(DF_flat['file'].values)\n",
    "reduce.config_file = dragons_rc\n",
    "# reduce.recipename = \"fabulous_recipe\"\n",
    "# print (f\"Using recipe {reduce.recipename}\")\n",
    "# reduce.runr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cf9f34d-3018-4a86-aac5-d84199ef9a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        str\n",
       "\u001b[0;31mString form:\u001b[0m _default\n",
       "\u001b[0;31mLength:\u001b[0m      8\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "str(object='') -> str\n",
       "str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
       "\n",
       "Create a new string object from the given object. If encoding or\n",
       "errors is specified, then the object must expose a data buffer\n",
       "that will be decoded using the given encoding and error handler.\n",
       "Otherwise, returns the result of object.__str__() (if defined)\n",
       "or repr(object).\n",
       "encoding defaults to sys.getdefaultencoding().\n",
       "errors defaults to 'strict'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce.recipename?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c776296-6635-4e74-b13e-cc2383c8c960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70988ccd-974d-4d42-86d1-e9f8f6ad27f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrations\t\t\t    S20210219S0077_flat.fits\n",
      "dragons_for_goats.db\t\t    S20210219S0077_overscanCorrected_crash.fits\n",
      "dragonsrc\t\t\t    S20210219S0078_ADUToElectrons.fits\n",
      "gmos_data_reduction.log\t\t    S20210219S0078_flat.fits\n",
      "S20210219S0077_ADUToElectrons.fits  S20210219S0078_overscanCorrected_crash.fits\n"
     ]
    }
   ],
   "source": [
    "## verify existence of intermediate data products (*_ADUToElectrons.fits)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632da6d-ae91-44ee-bcdf-8a11e04732c8",
   "metadata": {},
   "source": [
    "**Finally, one can have `interactive` parameter turned on for all relevant primitives of a given recipe as follows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b099cf-2e57-4fb0-a4fe-e0b8f8eb602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = Reduce()\n",
    "reduce.files.extend(DF_flat['file'].values)\n",
    "reduce.config_file = dragons_rc\n",
    "reduce.recipename = myrecipe\n",
    "reduce.uparms = [(\"interactive\", True)]\n",
    "print (f\"Using recipe {reduce.recipename}\")\n",
    "reduce.runr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ba44b-7872-42e4-abb8-e3fec935b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
